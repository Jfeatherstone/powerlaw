<!doctype html>
<html class="no-js" lang="en" data-content_root="../../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><link rel="index" title="Index" href="../../genindex.html" /><link rel="search" title="Search" href="../../search.html" />

    <!-- Generated with Sphinx 8.1.3 and Furo 2024.08.06 -->
        <title>powerlaw.distributions - powerlaw 1.6.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo.css?v=354aac6f" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo-extensions.css?v=302659d7" />
    <link rel="stylesheet" type="text/css" href="../../_static/overrides.css?v=e9ec496f" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../index.html"><div class="brand">powerlaw 1.6.0 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon no-toc" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../../index.html">
  
  
  <span class="sidebar-brand-text">powerlaw 1.6.0 documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials_top.html">Tutorials</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Tutorials</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/other_libraries.html">Differences with other libraries</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/loading_data.html">Loading data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/visualization.html">Visualization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/scaling_range.html">Identifying the scaling range</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/discrete_continuous.html">Continuous and discrete data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/ranges_and_constraints.html">Parameter Ranges and Constraints</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/comparing_distributions.html">Comparing distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/generating_data.html">Generating data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/advanced_topics.html">Advanced Topics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/warnings.html">Warnings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/new_distributions.html">Adding New Distributions</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../api.html">API</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of API</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../fit.html"><code class="docutils literal notranslate"><span class="pre">Fit</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../distributions.html"><code class="docutils literal notranslate"><span class="pre">Distribution</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../distributions.html#powerlaw.Power_Law"><code class="docutils literal notranslate"><span class="pre">Power_Law</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../distributions.html#powerlaw.Truncated_Power_Law"><code class="docutils literal notranslate"><span class="pre">Truncated_Power_Law</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../distributions.html#powerlaw.Exponential"><code class="docutils literal notranslate"><span class="pre">Exponential</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../distributions.html#powerlaw.Stretched_Exponential"><code class="docutils literal notranslate"><span class="pre">Stretched_Exponential</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../distributions.html#powerlaw.Lognormal"><code class="docutils literal notranslate"><span class="pre">Lognormal</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../distributions.html#powerlaw.Lognormal_Positive"><code class="docutils literal notranslate"><span class="pre">Lognormal_Positive</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../contributing.html">Contributing</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon no-toc" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <h1>Source code for powerlaw.distributions</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">nan</span>

<span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">types</span>
<span class="kn">import</span> <span class="nn">scipy.optimize</span>

<span class="kn">from</span> <span class="nn">.statistics</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">.plotting</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">.utils</span> <span class="kn">import</span> <span class="o">*</span>

<div class="viewcode-block" id="Distribution">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Distribution">[docs]</a>
<span class="k">class</span> <span class="nc">Distribution</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    An abstract class for theoretical probability distributions.</span>

<span class="sd">    Can be created with particular parameter values, or fitted to a dataset.</span>

<span class="sd">    Fitting is by maximum likelihood estimation by default, though can also</span>
<span class="sd">    be done by minimizing distance metrics (eg. Kolmogorov-Smirnov) between</span>
<span class="sd">    the theoretical and actual distribution.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : list or array, optional</span>
<span class="sd">        The data to which to fit the distribution. If provided, the fit will</span>
<span class="sd">        be created at initialization.</span>

<span class="sd">    xmin : int or float</span>
<span class="sd">        The data value beyond which the distribution is defined.</span>

<span class="sd">        Required for any distribution.</span>

<span class="sd">    xmax : int or float, optional</span>
<span class="sd">        The upper bound of the distribution.</span>

<span class="sd">        If not provided, the distribution will be assumed to be unbounded</span>
<span class="sd">        on the upper side.</span>

<span class="sd">    discrete : boolean, optional</span>
<span class="sd">        Whether the distribution is discrete (integers).</span>

<span class="sd">        Various approximations can be employed when there isn&#39;t an exact</span>
<span class="sd">        (or even approximate) expression for the PDF or CDF in the </span>
<span class="sd">        discrete case. See ``discrete_normalization`` for more information.</span>

<span class="sd">        Some distributions have approximation expressions for the parameters</span>
<span class="sd">        and/or RNG in discrete cases as well; see ``estimate_discrete``.</span>

<span class="sd">    fit_method : {&quot;likelihood&quot;, &quot;ks&quot;}, optional</span>
<span class="sd">        Method for fitting the distribution. ``&quot;likelihood&quot;`` is maximum likelihood</span>
<span class="sd">        estimation. ``&quot;ks&quot;`` is minimial distance estimation using the</span>
<span class="sd">        Kolmogorov-Smirnov test.</span>

<span class="sd">    parameters : array_like or dict, optional</span>
<span class="sd">        The parameters of the distribution. If data is given, these will</span>
<span class="sd">        be used as the initial parameters for fitting; otherwise, they</span>
<span class="sd">        will be taken as the final parameters for the distribution.</span>

<span class="sd">        Parameters can also be passed as keywords. Valid keywords for each</span>
<span class="sd">        distribution can be found in the ``parameter_names`` property of</span>
<span class="sd">        each distribution.</span>

<span class="sd">    parameter_ranges : dict, optional</span>
<span class="sd">        Dictionary of valid parameter ranges for fitting. Formatted as a</span>
<span class="sd">        dictionary of parameter names (eg. ``&#39;alpha&#39;``) and tuples/lists/etc.</span>
<span class="sd">        of their lower and upper limits (eg. ``(1.5, 2.5)``, ``(None, .1)``).</span>

<span class="sd">        The use of ``None`` is preferred over ``np.inf`` to indicate an</span>
<span class="sd">        unbounded limit.</span>

<span class="sd">    parameter_constraints : dict or list of dict</span>
<span class="sd">        Constraints amongst parameters during fitting. Constraint function(s)</span>
<span class="sd">        should take the distribution object as the only argument.</span>
<span class="sd">        The return value of the function should be some numerical value</span>
<span class="sd">        which is either 0 when the constraint is satisfied if an equality</span>
<span class="sd">        constraint, or a positive non-zero value when the constraint is</span>
<span class="sd">        satisfied if an inequality constraint.</span>

<span class="sd">        For example, if I want to enforce that ``param1`` is greater than</span>
<span class="sd">        ``param2``, I would define my function:</span>

<span class="sd">        .. code-block::</span>

<span class="sd">            def constraint(dist):</span>
<span class="sd">                return dist.param1 - dist.param2</span>

<span class="sd">            constraint_dict = {&quot;type&quot;: &#39;ineq&#39;,</span>
<span class="sd">                               &quot;fun&quot;: constraint}</span>

<span class="sd">        The dictionary (or dictionaries) should contain only the </span>
<span class="sd">        following keys:</span>

<span class="sd">        ``&quot;type&quot;``: The type of the constraint, either ``&quot;eq&quot;`` or</span>
<span class="sd">        ``&quot;ineq&quot;``.</span>

<span class="sd">        ``&quot;fun&quot;``&quot;: The function that implements the constraint.</span>

<span class="sd">        ``&quot;dists&quot;``: The name of the distributions that this constraint</span>
<span class="sd">        applies to. If not provided, constraint will be applied to</span>
<span class="sd">        all distributions.</span>

<span class="sd">        After some processsing and wrapping, these constraints are</span>
<span class="sd">        eventually sent to ``scipy.optimize.minimize(constraints=...)``;</span>
<span class="sd">        see their documentation for more information.</span>

<span class="sd">    discrete_normalization : {&quot;round&quot;, &quot;sum&quot;}, optional</span>
<span class="sd">        Approximation method to use in calculating the PDF (especially the</span>
<span class="sd">        PDF normalization constant) for a discrete distribution in the case</span>
<span class="sd">        that there is no analytical expression available.</span>

<span class="sd">        ``&quot;round&quot;`` uses the probability mass in the region ``[x - 0.5, x + 0.5]`` for each</span>
<span class="sd">        data point ``x``.</span>

<span class="sd">        ``&quot;sum&quot;`` simply sums the PDF over the defined range to compute the</span>
<span class="sd">        normalization.</span>

<span class="sd">    parent_Fit : Fit object, optional</span>
<span class="sd">        A Fit object from which to use data, if it exists.</span>

<span class="sd">    verbose : {0, 1, 2}, bool, optional</span>
<span class="sd">        Whether to print debug and status information. ``0`` or ``False`` means</span>
<span class="sd">        print no information (including no warnings), ``1`` or ``True`` means print</span>
<span class="sd">        only warnings, and ``2`` means print warnings and status messages.</span>

<span class="sd">    kwargs :</span>
<span class="sd">        Parameter values for specific distributions can be passed as</span>
<span class="sd">        keyword arguments.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">xmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">xmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">discrete</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">fit_method</span><span class="o">=</span><span class="s1">&#39;likelihood&#39;</span><span class="p">,</span>
                 <span class="n">parameters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">parameter_ranges</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">parameter_constraints</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">discrete_normalization</span><span class="o">=</span><span class="s1">&#39;round&#39;</span><span class="p">,</span>
                 <span class="n">parent_Fit</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                 <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>


        <span class="c1"># When defining a subclass of this one, you should define this</span>
        <span class="c1"># list as a property of the class</span>
        <span class="c1">#parameter_names = []</span>
        <span class="c1"># You also will need to define this in the subclass with the</span>
        <span class="c1"># upper and lower bound for each parameter.</span>
        <span class="c1">#DEFAULT_PARAMETER_RANGES = {}</span>
        <span class="c1"># (but we don&#39;t define them here because we don&#39;t want to overwrite</span>
        <span class="c1"># the values created in the subclass)</span>
        <span class="c1"># And the name of the distribution</span>
        <span class="c1">#name = &#39;name&#39;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">fit_method</span> <span class="o">=</span> <span class="n">fit_method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">discrete</span> <span class="o">=</span> <span class="n">discrete</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">discrete_normalization</span> <span class="o">=</span> <span class="n">discrete_normalization</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span>

        <span class="c1"># If our data is only integer values, but discrete is not true</span>
        <span class="c1"># or vice versa, give a warning</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">discrete</span> <span class="ow">and</span> <span class="nb">any</span><span class="p">(</span><span class="n">data</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)):</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;discrete=True but data does not exclusively contain integer values. Casting to integer...&#39;</span><span class="p">)</span>

        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">discrete</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span><span class="n">data</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)):</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;discrete=False but data exclusively contains integer values. Consider using discrete=True.&#39;</span><span class="p">)</span>

        <span class="c1"># We need an xmin, so we just set it to the minimum value of the</span>
        <span class="c1"># data if we don&#39;t get a specific value</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">xmin</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">xmin</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

            <span class="c1"># If we don&#39;t have data, then we need to raise an error.</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;No xmin provided, and no data to infer value from. Provide an explicit value for xmin!&#39;</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">xmin</span> <span class="o">=</span> <span class="n">xmin</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span> <span class="o">=</span> <span class="n">xmax</span>

        <span class="c1"># If we don&#39;t have a parent fit, we still have to make sure that</span>
        <span class="c1"># this variable gets assigned, otherwise we&#39;ll have logic issues</span>
        <span class="c1"># later on.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parent_Fit</span> <span class="o">=</span> <span class="n">parent_Fit</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent_Fit</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent_Fit</span><span class="o">.</span><span class="n">data</span>

        <span class="c1"># Crop the data to the domain, but make a copy of the original</span>
        <span class="c1"># first. This means we don&#39;t need to trim_to_range whenever</span>
        <span class="c1"># we access the data in the future.</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">original_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">trim_to_range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">xmin</span><span class="o">=</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="o">=</span><span class="n">xmax</span><span class="p">)</span>

        <span class="c1"># Setup the initial parameters and things</span>
        <span class="c1"># We have to pass the kwargs here because parameters might be</span>
        <span class="c1"># directly passed as keywords.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initialize_parameters</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># Setup the parameter ranges</span>
        <span class="c1"># This sets the variable `self.parameter_ranges`</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initialize_parameter_ranges</span><span class="p">(</span><span class="n">parameter_ranges</span><span class="p">)</span>

        <span class="c1"># Setup parameter contraints</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initialize_parameter_constraints</span><span class="p">(</span><span class="n">parameter_constraints</span><span class="p">)</span>

        <span class="c1"># This will be set in fit() to True if the fitting failed.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise_flag</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># Fit if we have data</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">):</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">debug_parameter_names</span><span class="p">()</span>

    
<div class="viewcode-block" id="Distribution.debug_parameter_names">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Distribution.debug_parameter_names">[docs]</a>
    <span class="k">def</span> <span class="nf">debug_parameter_names</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This is solely a debug function that sets up variables in the</span>
<span class="sd">        old format (from v1.5, eg. ``self.parameter1``).</span>

<span class="sd">        It should be removed in a future version along with an update to</span>
<span class="sd">        the test cases once it is convincing that the refactoring didn&#39;t</span>
<span class="sd">        fundamentally change anything.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parameter1</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parameter2</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parameter3</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parameter1_name</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parameter2_name</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parameter3_name</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameter_names</span><span class="p">)):</span> 
            <span class="c1"># Set the name</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;parameter</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">_name&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter_names</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

            <span class="c1"># Set the value</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;parameter</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter_names</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span></div>



<div class="viewcode-block" id="Distribution.initialize_parameters">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Distribution.initialize_parameters">[docs]</a>
    <span class="k">def</span> <span class="nf">initialize_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">initial_parameters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set up the parameters for the distribution.</span>

<span class="sd">        If parameters are passed, they will try to be parsed, otherwise</span>
<span class="sd">        initial guesses for parameters specific to each distribution will</span>
<span class="sd">        be used.</span>

<span class="sd">        Note that there is also a function ``set_parameters()`` in this class.</span>
<span class="sd">        The primary difference between the two is that this function allows</span>
<span class="sd">        the possibility of generating initial guesses of parameters</span>
<span class="sd">        (using the ``generate_initial_parameters()`` function), whereas</span>
<span class="sd">        the other method requires that parameter values are actually</span>
<span class="sd">        passed. Technically you could just use this one, but I figured</span>
<span class="sd">        it was more clear to have separate functions.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        initial_parameters : dict or array_like, optional</span>
<span class="sd">            A dictionary in which each key corresponds to a parameter</span>
<span class="sd">            name and the value corresponds to the initial value of that</span>
<span class="sd">            parameters.</span>

<span class="sd">            Can also be given as a list that is exactly the length of</span>
<span class="sd">            ``self.parameter_names``, and then the values in that list will</span>
<span class="sd">            be assumed as the initial values for the parameters in the</span>
<span class="sd">            same order as the former list.</span>

<span class="sd">            If not provided, the values will be initialized using</span>
<span class="sd">            ``self.generate_initial_parameters()`` which will try its best</span>
<span class="sd">            to give a reasonable start based on the data.</span>

<span class="sd">        kwargs : </span>
<span class="sd">            Parameters can be passed as direct keyword arguments as well.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Since the user may only specify a few parameters (not required to</span>
        <span class="c1"># set all of them, we should start with the default values).</span>
        <span class="c1"># This is only possible when we have data though</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">):</span>
            <span class="c1"># If we aren&#39;t given any initial parameters, try to generate</span>
            <span class="c1"># them from the data.</span>

            <span class="n">initial_parameters_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_initial_parameters</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">initial_parameters_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameter_names</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameter_names</span><span class="p">)))</span>

        <span class="c1"># If we were given a dictionary of initial parameters, we use</span>
        <span class="c1"># those values as is.</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">initial_parameters</span><span class="p">)</span> <span class="o">==</span> <span class="nb">dict</span><span class="p">:</span>
            <span class="c1"># Only choose the parameters that are actually for this class</span>
            <span class="c1"># (since we may be given parameters from a fit object that</span>
            <span class="c1"># contains information for other distributions).</span>
            <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">initial_parameters</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter_names</span><span class="p">:</span>
                    <span class="n">initial_parameters_dict</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>

        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">initial_parameters</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">initial_parameters</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameter_names</span><span class="p">):</span>
            <span class="c1"># If we are given a list of initial parameters, we assume</span>
            <span class="c1"># the order of them is the same as the order of self.parameter_names.</span>
            <span class="n">initial_parameters_dict</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameter_names</span><span class="p">,</span> <span class="n">initial_parameters</span><span class="p">)))</span>

        <span class="k">elif</span> <span class="n">initial_parameters</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># If initial_parameters is None, it&#39;s possible that the user</span>
            <span class="c1"># passed the parameter values through direct keywords.</span>
            <span class="k">for</span> <span class="n">kw</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">kw</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter_names</span><span class="p">:</span>
                    <span class="n">initial_parameters_dict</span><span class="p">[</span><span class="n">kw</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="n">kw</span><span class="p">]</span>

            <span class="c1"># It&#39;s also possible they just want to use the generated values</span>
            <span class="c1"># from generate_initial_parameters, in which case we do nothing</span>
            <span class="c1"># here.</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Otherwise, something must be wrong with the initial parameters</span>
            <span class="c1"># provided, so we raise an error.</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Invalid value provided for initial parameters: </span><span class="si">{</span><span class="n">initial_parameters</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">)</span>

        <span class="c1"># Let&#39;s make sure that we got some values, since it&#39;s possible we</span>
        <span class="c1"># could get to this point by passing no parameters and having</span>
        <span class="c1"># no data.</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">([</span><span class="n">value</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">initial_parameters_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()]):</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;Not enough information provided to assign parameters! Make sure to specific parameter </span><span class="se">\</span>
<span class="s1">                            values or pass data to generate them.&#39;</span><span class="p">)</span>

        <span class="c1"># Actually set the values</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter_names</span><span class="p">:</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">initial_parameters_dict</span><span class="p">[</span><span class="n">p</span><span class="p">])</span>
        
        <span class="c1"># We also replace initial_parameters with the proper dictionary,</span>
        <span class="c1"># since that is probably more useful</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initial_parameters</span> <span class="o">=</span> <span class="n">initial_parameters_dict</span></div>



<div class="viewcode-block" id="Distribution.set_parameters">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Distribution.set_parameters">[docs]</a>
    <span class="k">def</span> <span class="nf">set_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set the parameters for the distribution.</span>

<span class="sd">        Intended to be called during fitting, as opposed to</span>
<span class="sd">        ``initialize_parameters()`` which is designed to be called during</span>
<span class="sd">        construction. See documentation for this other function for more</span>
<span class="sd">        information.</span>

<span class="sd">        You could also manually set the parameters with something like:</span>

<span class="sd">            dist.param1 = ...</span>
<span class="sd">            dist.param2 = ...</span>

<span class="sd">        This function is totally equivalent to that, but just adds some</span>
<span class="sd">        parsing so you can pass the parameters in a list or dict form.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        params : dict or array-like</span>
<span class="sd">            A dictionary in which each key corresponds to a parameter</span>
<span class="sd">            name and the value corresponds to the initial value of that</span>
<span class="sd">            parameters.</span>

<span class="sd">            Can also be given as a list that is exactly the length of</span>
<span class="sd">            ``self.parameter_names``, and then the values in that list will</span>
<span class="sd">            be assumed as the initial values for the parameters in the</span>
<span class="sd">            same order as the former list.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># If we were given a dictionary of initial parameters, we use</span>
        <span class="c1"># those values as is.</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">params</span><span class="p">)</span> <span class="o">==</span> <span class="nb">dict</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">all</span><span class="p">([</span><span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter_names</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">params</span><span class="o">.</span><span class="n">keys</span><span class="p">()]),</span> <span class="sa">f</span><span class="s1">&#39;Invalid initial parameters given: </span><span class="si">{</span><span class="n">params</span><span class="si">}</span><span class="s1">&#39;</span>
            <span class="n">params_dict</span> <span class="o">=</span> <span class="n">params</span>

        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">params</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameter_names</span><span class="p">):</span>
            <span class="c1"># If we are given a list of initial parameters, we assume</span>
            <span class="c1"># the order of them is the same as the order of self.parameter_names.</span>
            <span class="n">params_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameter_names</span><span class="p">,</span> <span class="n">params</span><span class="p">))</span>
        
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Otherwise, something must be wrong with the parameters</span>
            <span class="c1"># provided, so we raise an error.</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Invalid value provided for setting parameters: </span><span class="si">{</span><span class="n">params</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter_names</span><span class="p">:</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">params_dict</span><span class="p">[</span><span class="n">p</span><span class="p">])</span></div>



    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A dictionary in which each key corresponds to a parameter</span>
<span class="sd">        name and the value corresponds to the initial value of that</span>
<span class="sd">        parameters.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameter_names</span><span class="p">,</span> <span class="p">[</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter_names</span><span class="p">]))</span>


<div class="viewcode-block" id="Distribution.initialize_parameter_ranges">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Distribution.initialize_parameter_ranges">[docs]</a>
    <span class="k">def</span> <span class="nf">initialize_parameter_ranges</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ranges</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set up the ranges for parameters for the distribution.</span>

<span class="sd">        If not provided, the default range for each parameter will be</span>
<span class="sd">        used; these are specific to each individual distribution. For</span>
<span class="sd">        more information, see the variable ``DEFAULT_PARAMETER_RANGES`` in</span>
<span class="sd">        children of this class.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        ranges : dict or array-like, optional</span>
<span class="sd">            A dictionary in which each key corresponds to a parameter</span>
<span class="sd">            name and the value corresponds to the lower and upper bound</span>
<span class="sd">            for that parameter (in the format of a length 2 tuple/list/array).</span>
<span class="sd">            Ranges can be provided for only some parameters.</span>

<span class="sd">            Can also be given as a list that is exactly the length of</span>
<span class="sd">            ``self.parameter_names``, and then the values in that list will</span>
<span class="sd">            be assumed as the lower and upper bound for the parameter</span>
<span class="sd">            with that same index in ``self.parameter_names``. As such,</span>
<span class="sd">            ranges must be given for all parameters if given as a list.</span>

<span class="sd">            If not provided, the values will be initialized using</span>
<span class="sd">            ``self.DEFAULT_PARAMETER_RANGES``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># We start with the default range, since it&#39;s possible that the</span>
        <span class="c1"># user has passed a range for only one or two parameters instead</span>
        <span class="c1"># of all of them. In that case, the parameters that haven&#39;t been</span>
        <span class="c1"># specified should follow their default range. Also we make a copy</span>
        <span class="c1"># so we don&#39;t change the original</span>
        <span class="n">ranges_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">DEFAULT_PARAMETER_RANGES</span><span class="p">)</span>

        <span class="c1"># If we were given a dictionary of ranges, we use</span>
        <span class="c1"># those values as is.</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">ranges</span><span class="p">)</span> <span class="o">==</span> <span class="nb">dict</span><span class="p">:</span>
            <span class="c1"># Only choose the parameter ranges that are actually for this class</span>
            <span class="c1"># (since we may be given parameters from a fit object that</span>
            <span class="c1"># contains information for other distributions).</span>
            <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">ranges</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter_names</span><span class="p">:</span>
                    <span class="n">ranges_dict</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>

        <span class="c1"># Have to make sure that ranges is a 2d list, which involves checking</span>
        <span class="c1"># that it has __iter__, it has at least one entry, and it&#39;s entry</span>
        <span class="c1"># has __iter__</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">ranges</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">ranges</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">ranges</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">ranges</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameter_names</span><span class="p">):</span>
            <span class="c1"># If we are given a list of initial parameters, we assume</span>
            <span class="c1"># the order of them is the same as the order of self.parameter_names.</span>
            <span class="n">ranges_dict</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameter_names</span><span class="p">,</span> <span class="n">ranges</span><span class="p">)))</span>

        <span class="k">elif</span> <span class="n">ranges</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Do nothing, since we already set the default ranges above.</span>
            <span class="k">pass</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Otherwise, something must be wrong with the ranges</span>
            <span class="c1"># provided, so we raise an error.</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Invalid value provided for parameter ranges: </span><span class="si">{</span><span class="n">ranges</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">parameter_ranges</span> <span class="o">=</span> <span class="n">ranges_dict</span></div>



<div class="viewcode-block" id="Distribution.generate_initial_parameters">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Distribution.generate_initial_parameters">[docs]</a>
    <span class="k">def</span> <span class="nf">generate_initial_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This function should be implemented in child classes to create an</span>
<span class="sd">        initial guess for each parameter based on the data passed either</span>
<span class="sd">        directly to this function, or to the class instance.</span>

<span class="sd">        This can&#39;t be implemented in this class because the specific</span>
<span class="sd">        parameters and their values will depend on what type of </span>
<span class="sd">        distribution you are working with.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        params : dict</span>
<span class="sd">            A dictionary where the keys are the parameter names and the values</span>
<span class="sd">            are the initial values of each parameter.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Of course remove this line when you reimplement this function.</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;generate_initial_parameters() not implemented&#39;</span><span class="p">)</span>

        <span class="n">params</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># Initialize your parameters here</span>
        <span class="c1"># ...</span>

        <span class="c1"># For example, for a power law, assuming f is a function that</span>
        <span class="c1"># guesses the exponent based on the data.</span>
        <span class="c1"># params[&quot;alpha&quot;] = f(data)</span>

        <span class="k">return</span> <span class="n">params</span></div>



<div class="viewcode-block" id="Distribution.initialize_parameter_constraints">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Distribution.initialize_parameter_constraints">[docs]</a>
    <span class="k">def</span> <span class="nf">initialize_parameter_constraints</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameter_constraints</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parse and save constraint functions for parameters to be used</span>
<span class="sd">        during the fitting process.</span>

<span class="sd">        The constraints are used in ``scipy.optimize.minimize()`` and so</span>
<span class="sd">        the end result follows the requirements for dictionary-type</span>
<span class="sd">        constraints described here, though with some slight modifications:</span>

<span class="sd">        https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        parameter_constraints : dict or list of dict</span>
<span class="sd">            Constraints amongst parameters during fitting. Constraint function(s)</span>
<span class="sd">            should take the distribution object as the only argument.</span>
<span class="sd">            The return value of the function should be some numerical value</span>
<span class="sd">            which is either 0 when the constraint is satisfied if an equality</span>
<span class="sd">            constraint, or a positive non-zero value when the constraint is</span>
<span class="sd">            satisfied if an inequality constraint.</span>

<span class="sd">            For example, if I want to enforce that ``param1`` is greater than</span>
<span class="sd">            ``param2``, I would define my function:</span>

<span class="sd">            .. code-block::</span>

<span class="sd">                def constraint(dist):</span>
<span class="sd">                    return dist.param1 - dist.param2</span>

<span class="sd">                constraint_dict = {&quot;type&quot;: &#39;ineq&#39;,</span>
<span class="sd">                                   &quot;fun&quot;: constraint}</span>

<span class="sd">            The dictionary (or dictionaries) should contain only the </span>
<span class="sd">            following keys:</span>

<span class="sd">            ``&quot;type&quot;``: The type of the constraint, either ``&quot;eq&quot;`` or</span>
<span class="sd">            ``&quot;ineq&quot;``.</span>

<span class="sd">            ``&quot;fun&quot;``&quot;: The function that implements the constraint.</span>

<span class="sd">            ``&quot;dists&quot;``: The name of the distributions that this constraint</span>
<span class="sd">            applies to. If not provided, constraint will be applied to</span>
<span class="sd">            all distributions.</span>

<span class="sd">            After some processsing and wrapping, these constraints are</span>
<span class="sd">            eventually sent to ``scipy.optimize.minimize(constraints=...)``;</span>
<span class="sd">            see their documentation for more information.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># The final constraint object we want is a list of dictionaries that can</span>
        <span class="c1"># be passed to scipy.optimize.minimize.</span>

        <span class="c1"># That being said, we have a few extra pieces of information we</span>
        <span class="c1"># want to pass, so even if we are passed a dictionary already, we</span>
        <span class="c1"># should parse all of the information, then create a new dictionary.</span>

        <span class="c1"># From each (if multiple) constraint function, we need the type,</span>
        <span class="c1"># (&#39;eq&#39; or &#39;ineq&#39;), the function itself, and whether that constraint</span>
        <span class="c1"># applies to this distribution.</span>
        <span class="n">functions_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">type_list</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">constraint_list</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># First, make a temporary list of the dictionaries if we don&#39;t already</span>
        <span class="c1"># have one.</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">parameter_constraints</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">type</span><span class="p">(</span><span class="n">parameter_constraints</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="nb">dict</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">parameter_constraints</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">constraint_list</span> <span class="o">=</span> <span class="n">parameter_constraints</span>

        <span class="k">elif</span> <span class="nb">type</span><span class="p">(</span><span class="n">parameter_constraints</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">dict</span><span class="p">:</span>
            <span class="n">constraint_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">parameter_constraints</span><span class="p">]</span>
       
        <span class="c1"># Make sure each entry is a dictionary (this will pass if the</span>
        <span class="c1"># length of constraint_list is zero).</span>
        <span class="k">assert</span> <span class="nb">all</span><span class="p">([</span><span class="nb">type</span><span class="p">(</span><span class="n">con</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">dict</span> <span class="k">for</span> <span class="n">con</span> <span class="ow">in</span> <span class="n">constraint_list</span><span class="p">]),</span> <span class="sa">f</span><span class="s1">&#39;List of constraints passed to </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1"> but not all are dictionaries.&#39;</span>

        <span class="c1"># Now we parse the information from each dictionary</span>
        <span class="k">for</span> <span class="n">con</span> <span class="ow">in</span> <span class="n">constraint_list</span><span class="p">:</span>
            <span class="c1"># This whole thing is wrapped in a try statement so we</span>
            <span class="c1"># can return a clearer error if the dictionary is formatted</span>
            <span class="c1"># weirdly.</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="c1"># If the dictionary has an entry &#39;dists&#39;, this should be</span>
                <span class="c1"># a list of the distributions to which this constraint</span>
                <span class="c1"># applies. So we only save the constraint if this entry</span>
                <span class="c1"># doesn&#39;t exist (implying it applies to all distributions)</span>
                <span class="c1"># or if the name of this dist is in there.</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="s1">&#39;dists&#39;</span> <span class="ow">in</span> <span class="n">con</span><span class="p">:</span>
                    <span class="n">functions_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">con</span><span class="p">[</span><span class="s2">&quot;fun&quot;</span><span class="p">])</span>
                    <span class="n">type_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">con</span><span class="p">[</span><span class="s2">&quot;type&quot;</span><span class="p">])</span>

                <span class="k">elif</span> <span class="s1">&#39;dists&#39;</span> <span class="ow">in</span> <span class="n">con</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">con</span><span class="p">[</span><span class="s2">&quot;dists&quot;</span><span class="p">],</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="n">con</span><span class="p">[</span><span class="s2">&quot;dists&quot;</span><span class="p">]:</span>
                    <span class="n">functions_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">con</span><span class="p">[</span><span class="s2">&quot;fun&quot;</span><span class="p">])</span>
                    <span class="n">type_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">con</span><span class="p">[</span><span class="s2">&quot;type&quot;</span><span class="p">])</span>

                <span class="c1"># Otherwise, we ignore this constraint</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">pass</span>

            <span class="k">except</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Malformed constraint dictionary passed to </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1">: received </span><span class="si">{</span><span class="n">con</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

        <span class="c1"># The final list of dictionaries we are building</span>
        <span class="n">constraint_dict_list</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Now that we have the constraints set up, we wrap them in an</span>
        <span class="c1"># outer function which allows us to pass the fit object as the</span>
        <span class="c1"># argument instead of the list of parameter values.</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">functions_list</span><span class="p">)):</span>

            <span class="c1"># Globals obviously aren&#39;t good practice, but this is the</span>
            <span class="c1"># only way I can imagine that we gain access to the whole</span>
            <span class="c1"># Distribution object within the constraint function in</span>
            <span class="c1"># scipy.optimize.minimize.</span>
            <span class="n">function</span> <span class="o">=</span> <span class="n">functions_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="k">global</span> <span class="n">class_instance</span>
            <span class="n">class_instance</span> <span class="o">=</span> <span class="bp">self</span>

            <span class="k">def</span> <span class="nf">wrapped_function</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
                <span class="c1"># We aren&#39;t actually going to use these params</span>
                <span class="c1"># but will load our global class instance and pass that.</span>
                <span class="k">global</span> <span class="n">class_instance</span>
                <span class="k">return</span> <span class="n">function</span><span class="p">(</span><span class="n">class_instance</span><span class="p">)</span>

            <span class="n">constraint_dict_list</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="n">type_list</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                                         <span class="s2">&quot;fun&quot;</span><span class="p">:</span> <span class="n">wrapped_function</span><span class="p">})</span>

        <span class="c1"># Save the constraints</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parameter_constraints</span> <span class="o">=</span> <span class="n">constraint_dict_list</span></div>



<div class="viewcode-block" id="Distribution.fit">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Distribution.fit">[docs]</a>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Numerically fits the parameters of the distribution to the data.</span>

<span class="sd">        Fitting is performed by minimizing either the loglikelihood or</span>
<span class="sd">        KS distance (depending on the value of ``Distribution.fit_method``).</span>

<span class="sd">        Bounds defined in ``self.parameter_ranges`` are used explicitly during</span>
<span class="sd">        the minimization process.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : array_like, optional</span>
<span class="sd">            The data to fit the distribution to, if different from the</span>
<span class="sd">            data used to initialize the class.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># The passed data takes precedence, but otherwise we use the data</span>
        <span class="c1"># stored in the class instance.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">):</span>
            <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span>

        <span class="c1"># If we still don&#39;t have data, raise an error</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;No data to fit distribution (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1">) to!&#39;</span><span class="p">)</span>

        <span class="c1"># self.data is already trimmed, but if we are passed new data</span>
        <span class="c1"># we need to trim it.</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">trim_to_range</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">xmin</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">)</span>

        <span class="c1"># Define our cost function based on the fitting method we&#39;ve chosen.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_method</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;likelihood&#39;</span><span class="p">:</span>

            <span class="k">def</span> <span class="nf">fit_function</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
                <span class="c1"># Set the parameters</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">set_parameters</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
                <span class="c1"># Compute log likelihood</span>
                <span class="n">cost</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loglikelihoods</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
                <span class="k">return</span> <span class="n">cost</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_method</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;ks&#39;</span><span class="p">:</span>

            <span class="k">def</span> <span class="nf">fit_function</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
                <span class="c1"># Set the parameters</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">set_parameters</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
                <span class="c1"># Compute Kolmogorov-Smirnov </span>
                <span class="bp">self</span><span class="o">.</span><span class="n">compute_distance_metrics</span><span class="p">()</span>
                <span class="n">cost</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">D</span>
                <span class="k">return</span> <span class="n">cost</span>

        <span class="c1"># Format the bounds as required for scipy&#39;s minimize</span>
        <span class="n">bounds</span> <span class="o">=</span> <span class="p">[</span><span class="n">b</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter_ranges</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>

        <span class="c1"># In choosing the minimization method, unfortunately there isn&#39;t</span>
        <span class="c1"># one choice that works for all cases. The old method (see below)</span>
        <span class="c1"># uses Nelder-Mead.</span>

        <span class="c1"># Powell and Nelder-Mead </span>
        <span class="c1"># together cover most options though is what I&#39;ve found.</span>
        <span class="c1"># In particular, Powell can traverse the inflection point at</span>
        <span class="c1"># alpha = 1 only going down (ie works for any alpha &lt;= 1) whereas</span>
        <span class="c1"># Nelder-Mead can only traverse it going up (ie. works for any</span>
        <span class="c1"># alpha &gt; 1).</span>

        <span class="c1"># The only options I&#39;ve found that have success both ways is</span>
        <span class="c1"># COBYLA and COBYQA. COBYQA struggles around alpha = 1, but</span>
        <span class="c1"># COBYLA seems relatively fine, but struggles with lognormal fitting.</span>
        <span class="c1"># I also find that it actually does a better job of fitting</span>
        <span class="c1"># exponentials, but this means that the tests fail because it</span>
        <span class="c1"># does better than it used to...</span>

        <span class="c1"># Maybe it sounds dumb, but an alternative is to switch between</span>
        <span class="c1"># two algorithms a few times, since, for example, both Nelder-Mead and Powell</span>
        <span class="c1"># will work in each domain (so long as they don&#39;t need to traverse</span>
        <span class="c1"># alpha = 1).</span>
        <span class="c1"># This combination works well for values close to 1 from below</span>
        <span class="c1"># (eg. 0.98) but not for values from above (eg. 1.02). Maybe</span>
        <span class="c1"># there is some way to fix this; I think the issue stems from</span>
        <span class="c1"># inaccuracy in the pdf normalization. For now, this can be</span>
        <span class="c1"># sort of addressed by using `discrete=True` since this just</span>
        <span class="c1"># calculates the normalization numerically.</span>

        <span class="c1"># After testing, I think sticking with Nelder-Mead for now is fine,</span>
        <span class="c1"># unless we have a constraint, then we use COBYLA (since Nelder-Mead</span>
        <span class="c1"># can&#39;t handle constraints). But this should definitely be reviewed</span>
        <span class="c1"># later on.</span>
        <span class="c1">#methods = [&quot;Powell&quot;, &quot;Nelder-Mead&quot;]</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameter_constraints</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameter_constraints</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1">#methods = [&quot;COBYLA&quot;]</span>
            <span class="n">methods</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;SLSQP&quot;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">methods</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Nelder-Mead&#39;</span><span class="p">]</span>

        <span class="c1"># Only switch back and forth if we have more than one method.</span>
        <span class="n">switches</span> <span class="o">=</span> <span class="mi">2</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">methods</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="mi">1</span>

        <span class="c1"># Take the initial parameters</span>
        <span class="n">parameters</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">switches</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">methods</span><span class="p">:</span>
                <span class="n">result</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">optimize</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">fit_function</span><span class="p">,</span>
                                                 <span class="n">x0</span><span class="o">=</span><span class="n">parameters</span><span class="p">,</span>
                                                 <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">,</span>
                                                 <span class="n">method</span><span class="o">=</span><span class="n">m</span><span class="p">,</span>
                                                 <span class="n">constraints</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parameter_constraints</span><span class="p">,</span>
                                                 <span class="n">tol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>
                <span class="n">parameters</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">x</span>

        <span class="c1"># In case you&#39;d like to compare, this uses the exact same optimization</span>
        <span class="c1"># as in powerlaw v1.5 and before (Nelder-Mead). The results end up pretty much</span>
        <span class="c1"># the same as with the new method above. This method is slightly</span>
        <span class="c1"># faster than the one above when using two methods above and 2</span>
        <span class="c1"># switches. COBYLA is comparable in speed.</span>
        <span class="c1">#self.initialize_parameters()</span>
        <span class="c1">#initial_parameters = list(self.parameters.values())</span>

        <span class="c1">#parameters, negative_loglikelihood, iter, funcalls, warnflag, = \</span>
        <span class="c1">#        scipy.optimize.fmin(</span>
        <span class="c1">#                        lambda params: fit_function(params),</span>
        <span class="c1">#                        initial_parameters,</span>
        <span class="c1">#                        full_output=1,</span>
        <span class="c1">#                        disp=False)</span>


        <span class="c1"># Save the optimized parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_parameters</span><span class="p">(</span><span class="n">parameters</span><span class="p">)</span>

        <span class="c1"># Flag as noisy (not fit) if the parameters aren&#39;t in range</span>
        <span class="c1"># If you switch to the old optimization method, make sure to</span>
        <span class="c1"># comment out the second term in this expression.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise_flag</span> <span class="o">=</span> <span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_range</span><span class="p">())</span> <span class="ow">or</span> <span class="p">(</span><span class="ow">not</span> <span class="n">result</span><span class="o">.</span><span class="n">success</span><span class="p">)</span>
  
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_flag</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;No valid fits found for distribution </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

        <span class="c1"># Recompute goodness of fit metrics</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loglikelihood</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loglikelihoods</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">compute_distance_metrics</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="c1"># Give a warning if the fit parameters are very close to the</span>
        <span class="c1"># boundaries, indicating that the parameter ranges are probably</span>
        <span class="c1"># wrong.</span>

        <span class="c1"># The small value to check if we are close to the boundary.</span>
        <span class="c1"># Doesn&#39;t actually need to be that small, just enough to see that</span>
        <span class="c1"># the value is close to the edge.</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="mf">1e-2</span>
        <span class="n">nearBoundary</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="c1"># TODO Should there be different behavior is a limit is 0? So that</span>
        <span class="c1"># we don&#39;t trigger this warning just from having a (possibly totally</span>
        <span class="c1"># reasonable) small value? Maybe make eps scale with the magnitude</span>
        <span class="c1"># of the parameter value?</span>

        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter_names</span><span class="p">:</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter_ranges</span><span class="p">[</span><span class="n">p</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">nearBoundary</span> <span class="o">+=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span> <span class="o">-</span> <span class="n">eps</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter_ranges</span><span class="p">[</span><span class="n">p</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter_ranges</span><span class="p">[</span><span class="n">p</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">nearBoundary</span> <span class="o">+=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span> <span class="o">+</span> <span class="n">eps</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter_ranges</span><span class="p">[</span><span class="n">p</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">nearBoundary</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">noise_flag</span> <span class="o">=</span> <span class="kc">True</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;Fitted parameters are very close to the edge of parameter ranges; consider changing these ranges.&#39;</span><span class="p">)</span></div>



<div class="viewcode-block" id="Distribution.KS">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Distribution.KS">[docs]</a>
    <span class="k">def</span> <span class="nf">KS</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return the Kolmogorov-Smirnov distance D.</span>

<span class="sd">        Included for backwards compatability; this method has been</span>
<span class="sd">        renamed ``compute_distance_metrics()`` because it computes several</span>
<span class="sd">        distance metrics (including KS).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">compute_distance_metrics</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">D</span></div>


    
<div class="viewcode-block" id="Distribution.compute_distance_metrics">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Distribution.compute_distance_metrics">[docs]</a>
    <span class="k">def</span> <span class="nf">compute_distance_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute various distance metrics between the fit distribution and</span>
<span class="sd">        the actual distribution of data.</span>

<span class="sd">        The following distance metrics will be computed, with :math:`C_d`</span>
<span class="sd">        and :math:`C_t` as the cumulative distribution function for the</span>
<span class="sd">        data and for the theoretical fit, respectively.</span>

<span class="sd">        Kolmogorov-Smirnov distance:</span>

<span class="sd">        .. math::</span>
<span class="sd">            D = max( max(C_d - C_t), -min(C_d - C_t) )</span>
<span class="sd">         </span>
<span class="sd">        Kuiper distance:</span>

<span class="sd">        .. math::</span>
<span class="sd">            V = max(C_d - C_t) - min(C_d - C_t)</span>

<span class="sd">        Anderson-Darling distance:</span>

<span class="sd">        .. math::</span>
<span class="sd">            A^2 = \sum( (C_d - C_t)^2 / (C_t (1 - C_t)))</span>

<span class="sd">        Kappa:</span>

<span class="sd">        .. math::</span>
<span class="sd">            K = 1 + mean(C_d - C_t)</span>

<span class="sd">        The names of these distance metrics will be stored as ``D``, ``V``, </span>
<span class="sd">        ``Asquare``, and ``Kappa`` respectively.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : list or array, optional</span>
<span class="sd">            If not provided, attempts to use the data passed on creation</span>
<span class="sd">            of the Distribution object.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># The passed data takes precedence, but otherwise we use the data</span>
        <span class="c1"># stored in the class instance.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">):</span>
            <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span>

        <span class="c1"># If we still don&#39;t have data, raise an error</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;No data to compute distance metrics for in distribution </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1">!&#39;</span><span class="p">)</span>

        <span class="c1"># self.data is already trimmed, but if we are passed new data</span>
        <span class="c1"># we need to trim it.</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">trim_to_range</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">xmin</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">)</span>

        <span class="c1"># If we don&#39;t have enough data, return a bunch of nan values</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Not enough data to compute distance metrics like Kolmogorov-Smirnov distance, returning nan.&quot;</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">D</span> <span class="o">=</span> <span class="n">nan</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">D_plus</span> <span class="o">=</span> <span class="n">nan</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">D_minus</span> <span class="o">=</span> <span class="n">nan</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Kappa</span> <span class="o">=</span> <span class="n">nan</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">V</span> <span class="o">=</span> <span class="n">nan</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Asquare</span> <span class="o">=</span> <span class="n">nan</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">D</span>

        <span class="c1"># In order to compute KS and other distance metrics, we need the</span>
        <span class="c1"># cumulative distribution function for the real data, as well as</span>
        <span class="c1"># for the fit distribution.</span>

        <span class="c1"># If we have a parent fit, the one for the real data should already</span>
        <span class="c1"># have been calculated.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent_Fit</span><span class="p">:</span>
            <span class="n">bins</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent_Fit</span><span class="o">.</span><span class="n">fitting_cdf_bins</span>
            <span class="n">Actual_CDF</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent_Fit</span><span class="o">.</span><span class="n">fitting_cdf</span>
            <span class="c1"># But since xmin may be specific to this distribution, not the</span>
            <span class="c1"># parent fit, we need to do the filtering here.</span>
            <span class="n">ind</span> <span class="o">=</span> <span class="n">bins</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmin</span>
            <span class="n">bins</span> <span class="o">=</span> <span class="n">bins</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span>
            <span class="n">Actual_CDF</span> <span class="o">=</span> <span class="n">Actual_CDF</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span>

            <span class="c1"># And we remove all the probability that was contained in</span>
            <span class="c1"># bins before xmin</span>
            <span class="n">dropped_probability</span> <span class="o">=</span> <span class="n">Actual_CDF</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">Actual_CDF</span> <span class="o">-=</span> <span class="n">dropped_probability</span>
            <span class="n">Actual_CDF</span> <span class="o">/=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">dropped_probability</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># If we don&#39;t have the cdf already computed, we compute it now</span>
            <span class="n">bins</span><span class="p">,</span> <span class="n">Actual_CDF</span> <span class="o">=</span> <span class="n">cdf</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="c1"># Now compute the theoretical cdf of the fit distribution</span>
        <span class="n">Theoretical_CDF</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">bins</span><span class="p">)</span>

        <span class="n">CDF_diff</span> <span class="o">=</span> <span class="n">Theoretical_CDF</span> <span class="o">-</span> <span class="n">Actual_CDF</span>

        <span class="c1"># Compute the various metrics of distance between the two</span>
        <span class="c1"># distributions based on the difference in CDFs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">D_plus</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">CDF_diff</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">D_minus</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">CDF_diff</span><span class="p">)</span>

        <span class="c1"># Not sure if this metric has a proper name, it&#39;s not mentioned</span>
        <span class="c1"># anywhere in the documentation.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Kappa</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">CDF_diff</span><span class="p">)</span>

        <span class="c1"># Kolmogorov-Smirnov distance, D</span>
        <span class="c1"># Insensitive to differences at the tails of the distributions.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">D</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">D_plus</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">D_minus</span><span class="p">)</span>

        <span class="c1"># Kuiper distance, V</span>
        <span class="c1"># Gives additional weight to the tails, but mostly performs the</span>
        <span class="c1"># same as the KS distance</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">V</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">D_plus</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">D_minus</span>

        <span class="c1"># Anderson-Darling distance, Asquare</span>
        <span class="c1"># Very conservative distance metric, so only works well with</span>
        <span class="c1"># lots of points.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Asquare</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span>
                            <span class="p">(</span><span class="n">CDF_diff</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span>
                            <span class="p">(</span><span class="n">Theoretical_CDF</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">Theoretical_CDF</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-12</span><span class="p">)</span>
                            <span class="p">)[</span><span class="mi">1</span><span class="p">:]</span>
                             <span class="p">)</span></div>


        <span class="c1"># We don&#39;t return anything, just compute the values</span>


<div class="viewcode-block" id="Distribution.ccdf">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Distribution.ccdf">[docs]</a>
    <span class="k">def</span> <span class="nf">ccdf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The complementary cumulative distribution function (CCDF) of the</span>
<span class="sd">        theoretical distribution. Calculated for the values given in data</span>
<span class="sd">        between xmin and xmax, if present.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : list or array, optional</span>
<span class="sd">            The data for which to compute the CCDF. If not provided, the data</span>
<span class="sd">            passed on creation (if available) will be used.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        probabilities : numpy.ndarray</span>
<span class="sd">            The portion of the data that is greater than or equal to X.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">)</span></div>



<div class="viewcode-block" id="Distribution.cdf">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Distribution.cdf">[docs]</a>
    <span class="k">def</span> <span class="nf">cdf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The cumulative distribution function (CDF) of the theoretical</span>
<span class="sd">        distribution. Calculated for the values given in data within xmin and</span>
<span class="sd">        xmax, if present.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : array_like, optional</span>
<span class="sd">            The data for which to compute the CDF. If not provided, the data</span>
<span class="sd">            passed on creation (if available) will be used.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        probabilities : numpy.ndarray</span>
<span class="sd">            The portion of the data that is less than or equal to X.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># The passed data takes precedence, but otherwise we use the data</span>
        <span class="c1"># stored in the class instance.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">):</span>
            <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span>

        <span class="c1"># self.data is already trimmed, but if we are passed new data</span>
        <span class="c1"># we need to trim it.</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">trim_to_range</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">xmin</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">)</span>

        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;No data points in defined range of the distribution.&#39;</span><span class="p">)</span>

        <span class="c1"># If we aren&#39;t in range, we just return a bunch of (nearly) zeros</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_range</span><span class="p">():</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="mi">10</span><span class="o">**</span><span class="n">sys</span><span class="o">.</span><span class="n">float_info</span><span class="o">.</span><span class="n">min_10_exp</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cdf_xmin</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># If cdf_xmin is 1, it means we don&#39;t have the numerical accuracy to</span>
            <span class="c1"># calculate this tail. So we make everything 1, indicating</span>
            <span class="c1"># we&#39;re at the end of the tail. Such an xmin should be thrown</span>
            <span class="c1"># out by the KS test.</span>
            <span class="n">CDF</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">CDF</span>

        <span class="n">CDF</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cdf_base_function</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cdf_xmin</span>

        <span class="n">norm</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cdf_xmin</span>
        <span class="c1"># If we have an xmax, our normalization is slightly different</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">:</span>
            <span class="n">norm</span> <span class="o">=</span> <span class="n">norm</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cdf_base_function</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">))</span>

        <span class="n">CDF</span> <span class="o">=</span> <span class="n">CDF</span><span class="o">/</span><span class="n">norm</span>

        <span class="c1"># If we have any nan values in the cdf, it is indicative of a</span>
        <span class="c1"># numerical error, so we should warn.</span>
        <span class="c1"># np.min will always give nan if there are any nans</span>
        <span class="n">possible_numerical_error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">CDF</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">possible_numerical_error</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Likely underflow or overflow error: the optimal fit for this distribution gives values that are so extreme that we lack the numerical precision to calculate them.&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">CDF</span></div>



    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_cdf_xmin</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The CDF evaluated at the point ``xmin``; also the minimum value</span>
<span class="sd">        of the CDF.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cdf_base_function</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="p">)</span>


<div class="viewcode-block" id="Distribution.pdf">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Distribution.pdf">[docs]</a>
    <span class="k">def</span> <span class="nf">pdf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The probability density function (normalized histogram) of the</span>
<span class="sd">        theoretical distribution for the values in data within ``xmin`` and</span>
<span class="sd">        ``xmax``, if present.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : array_like, optional</span>
<span class="sd">            The data for which to compute the PDF. If not provided, the data</span>
<span class="sd">            passed on creation (if available) will be used.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        probabilities : numpy.ndarray</span>
<span class="sd">            The portion of the data that is contained at each bin (data point).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># The passed data takes precedence, but otherwise we use the data</span>
        <span class="c1"># stored in the class instance.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">):</span>
            <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span>

        <span class="c1"># self.data is already trimmed, but if we are passed new data</span>
        <span class="c1"># we need to trim it.</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">trim_to_range</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">xmin</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">)</span>

        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;No data points in defined range of the distribution.&#39;</span><span class="p">)</span>

        <span class="c1"># If we aren&#39;t in range, we just return a bunch of (nearly) zeros</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_range</span><span class="p">():</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="mi">10</span><span class="o">**</span><span class="n">sys</span><span class="o">.</span><span class="n">float_info</span><span class="o">.</span><span class="n">min_10_exp</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>

        <span class="c1"># If we have a continuous distribution, we can easily apply</span>
        <span class="c1"># our base function and the normalization factor to get the</span>
        <span class="c1"># pdf evaluated at each data point.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">discrete</span><span class="p">:</span>
            <span class="n">f</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pdf_base_function</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">C</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pdf_continuous_normalizer</span>

            <span class="n">likelihoods</span> <span class="o">=</span> <span class="n">f</span><span class="o">*</span><span class="n">C</span>

        <span class="c1"># For discrete cases, it&#39;s a little more tricky since we will</span>
        <span class="c1"># have to approximate the normalization factor.</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># If we have an explicit expression for the discrete</span>
            <span class="c1"># normalization, we should of course use that.</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pdf_discrete_normalizer</span><span class="p">:</span>
                <span class="n">f</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pdf_base_function</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
                <span class="n">C</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pdf_discrete_normalizer</span>

                <span class="n">likelihoods</span> <span class="o">=</span> <span class="n">f</span><span class="o">*</span><span class="n">C</span>

            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">discrete_normalization</span> <span class="o">==</span> <span class="s1">&#39;round&#39;</span><span class="p">:</span>
                <span class="c1"># If we want to approximate by rounding values, we essentially</span>
                <span class="c1"># take a discretized derivative of the cumulative distribution</span>
                <span class="c1"># function.</span>
                <span class="n">lower_data</span> <span class="o">=</span> <span class="n">data</span> <span class="o">-</span> <span class="mf">0.5</span>
                <span class="n">upper_data</span> <span class="o">=</span> <span class="n">data</span> <span class="o">+</span> <span class="mf">0.5</span>

                <span class="c1"># Temporarily expand xmin and xmax to be able to grab the extra bit of</span>
                <span class="c1"># probability mass beyond the (integer) values of xmin and xmax</span>
                <span class="c1"># Note this is a design decision. One could also say this extra</span>
                <span class="c1"># probability &quot;off the edge&quot; of the distribution shouldn&#39;t be included,</span>
                <span class="c1"># and that implementation is retained below, commented out. Note, however,</span>
                <span class="c1"># that such a cliff means values right at xmin and xmax have half the width to</span>
                <span class="c1"># grab probability from, and thus are lower probability than they would otherwise</span>
                <span class="c1"># be. This is particularly concerning for values at xmin, which are typically</span>
                <span class="c1"># the most likely and greatly influence the distribution&#39;s fit.</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">xmin</span> <span class="o">-=</span> <span class="mf">0.5</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span> <span class="o">+=</span> <span class="mf">0.5</span>

                <span class="n">likelihoods</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">upper_data</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">lower_data</span><span class="p">)</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">xmin</span> <span class="o">+=</span> <span class="mf">0.5</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span> <span class="o">-=</span> <span class="mf">0.5</span>

            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">discrete_normalization</span> <span class="o">==</span> <span class="s1">&#39;sum&#39;</span><span class="p">:</span>
                <span class="c1"># Otherwise, we just normalize numerically by summing the</span>
                <span class="c1"># PDF</span>

                <span class="c1"># There used to be the option to pass a specific upper_limit</span>
                <span class="c1"># value in the discrete_normalization keyword, but I don&#39;t</span>
                <span class="c1"># think that is actually useful. Passed values above xmax</span>
                <span class="c1"># wouldn&#39;t be useful since we don&#39;t have any data there, </span>
                <span class="c1"># and values below xmax would be confusing since there is</span>
                <span class="c1"># already a well-defined upper limit here: xmax.</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">:</span>
                    <span class="n">upper_limit</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">upper_limit</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

                <span class="c1"># Compute the pdf for all possible values, ie. assuming</span>
                <span class="c1"># we have perfected sampled our distribution.</span>
                <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="p">,</span> <span class="n">upper_limit</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">PDF</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pdf_base_function</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

                <span class="c1"># Then normalize using the &#39;perfect&#39; distribution, but</span>
                <span class="c1"># only take PDF values where we actually have data.</span>
                <span class="n">PDF</span> <span class="o">=</span> <span class="p">(</span><span class="n">PDF</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">PDF</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
                <span class="n">likelihoods</span> <span class="o">=</span> <span class="n">PDF</span><span class="p">[(</span><span class="n">data</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)]</span>

        <span class="c1"># Set any zeros to very small values</span>
        <span class="n">likelihoods</span><span class="p">[</span><span class="n">likelihoods</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">10</span><span class="o">**</span><span class="n">sys</span><span class="o">.</span><span class="n">float_info</span><span class="o">.</span><span class="n">min_10_exp</span>

        <span class="k">return</span> <span class="n">likelihoods</span></div>



    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_pdf_continuous_normalizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The (inverse of the) normalization constant for the PDF</span>
<span class="sd">        assuming a continuous distribution. So you can get the normalized</span>
<span class="sd">        PDF evaluated for a particular ``x`` as:</span>

<span class="sd">            _pdf_continuous_normalizer * _pdf_base_function(x)</span>

<span class="sd">        The implementation below simply uses the cumulative distribution</span>
<span class="sd">        function to compute this, though if an explicit expression can</span>
<span class="sd">        be found by integrating the PDF, this function should be overwritten</span>
<span class="sd">        in the child class.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Essentially equivalent to numerically integrating the pdf over</span>
        <span class="c1"># the whole domain.</span>
        <span class="n">C</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cdf_xmin</span>

        <span class="c1"># If the upper limit of the normalization is xmax instead of</span>
        <span class="c1"># infinity, account for that.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">:</span>
            <span class="n">C</span> <span class="o">-=</span> <span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cdf_base_function</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xmax</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Take the inverse so we can just multiply</span>
        <span class="k">return</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">C</span>


    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_pdf_discrete_normalizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The (inverse of the) normalization constant for the PDF</span>
<span class="sd">        assuming a discrete distribution.</span>

<span class="sd">        It is not currently implemented since the value will depend on your</span>
<span class="sd">        specific distribution, so it should be implemented in child classes.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="kc">False</span>


<div class="viewcode-block" id="Distribution.in_range">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Distribution.in_range">[docs]</a>
    <span class="k">def</span> <span class="nf">in_range</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Whether the current parameters (``self.parameters``) of the</span>
<span class="sd">        distribution are within the range of valid parameters (defined by</span>
<span class="sd">        ``self.parameter_ranges``) and satisfy any constraints provided</span>
<span class="sd">        (defined by ``self.parameter_constraints``)</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        result : bool</span>
<span class="sd">            True if all parameters are within the specified ranges and all</span>
<span class="sd">            constraints are satisfied.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Final result of whether all of the parameters are in range</span>
        <span class="n">result</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="c1"># Check if parameters are in range</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter_names</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter_ranges</span><span class="p">[</span><span class="n">p</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">result</span> <span class="o">*=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter_ranges</span><span class="p">[</span><span class="n">p</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter_ranges</span><span class="p">[</span><span class="n">p</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">result</span> <span class="o">*=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter_ranges</span><span class="p">[</span><span class="n">p</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># Check if constraints are satisfied.</span>
        <span class="k">for</span> <span class="n">con</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter_constraints</span><span class="p">:</span>
            <span class="c1"># For equality constraints, we make sure the value is zero</span>
            <span class="k">if</span> <span class="n">con</span><span class="p">[</span><span class="s2">&quot;type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;eq&#39;</span><span class="p">:</span>
                <span class="n">result</span> <span class="o">*=</span> <span class="n">con</span><span class="p">[</span><span class="s2">&quot;fun&quot;</span><span class="p">](</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span> <span class="o">==</span> <span class="mi">0</span>

            <span class="c1"># For inequality, we make sure the value is non negative</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">result</span> <span class="o">*=</span> <span class="n">con</span><span class="p">[</span><span class="s2">&quot;fun&quot;</span><span class="p">](</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span> <span class="o">&gt;</span> <span class="mi">0</span>

        <span class="k">return</span> <span class="nb">bool</span><span class="p">(</span><span class="n">result</span><span class="p">)</span></div>



<div class="viewcode-block" id="Distribution.likelihoods">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Distribution.likelihoods">[docs]</a>
    <span class="k">def</span> <span class="nf">likelihoods</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The likelihoods of the observed data from the theoretical distribution.</span>
<span class="sd">        Another name for the probabilities or probability density function.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : array_like, optional</span>
<span class="sd">            The data for which to compute the PDF. If not provided, the data</span>
<span class="sd">            passed on creation (if available) will be used.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        likelihoods : numpy.ndarray</span>
<span class="sd">            Likelihood of each observed data.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># No need to trim to range or check if data is None because pdf()</span>
        <span class="c1"># does that.</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">data</span><span class="p">)</span></div>



<div class="viewcode-block" id="Distribution.loglikelihoods">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Distribution.loglikelihoods">[docs]</a>
    <span class="k">def</span> <span class="nf">loglikelihoods</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The logarithm of the likelihoods of the observed data from the</span>
<span class="sd">        theoretical distribution.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : array_like, optional</span>
<span class="sd">            The data for which to compute the PDF. If not provided, the data</span>
<span class="sd">            passed on creation (if available) will be used.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        likelihoods : numpy.ndarray</span>
<span class="sd">            Logarithm (base e) of likelihood of each observed data.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># No need to trim to range or check if data is None because pdf()</span>
        <span class="c1"># does that, which is called by self.likelihoods().</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">likelihoods</span><span class="p">(</span><span class="n">data</span><span class="p">))</span></div>



<div class="viewcode-block" id="Distribution.plot_ccdf">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Distribution.plot_ccdf">[docs]</a>
    <span class="k">def</span> <span class="nf">plot_ccdf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Plot the complementary cumulative distribution function (CCDF) of the</span>
<span class="sd">        theoretical distribution for the values given in data within ``xmin``</span>
<span class="sd">        and ``xmax``, if present.</span>

<span class="sd">        Plots to a new figure or to axis ``ax`` if provided.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : array_like, optional</span>
<span class="sd">            The data for which to compute the PDF. If not provided, the data</span>
<span class="sd">            passed on creation (if available) will be used.</span>

<span class="sd">        ax : matplotlib axis, optional</span>
<span class="sd">            The axis on which to plot. If None, a new figure is created.</span>

<span class="sd">        kwargs</span>
<span class="sd">            Other keyword arguments are passed to ``matplotlib.pyplot.plot()``.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ax : matplotlib axis</span>
<span class="sd">            The axis on which the plot was made.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># The passed data takes precedence, but otherwise we use the data</span>
        <span class="c1"># stored in the class instance.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">):</span>
            <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span>

        <span class="c1"># If we have data, we use that for the bins</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">):</span>
            <span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">trim_to_range</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">xmin</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">))</span>

        <span class="c1"># Otherwise, we just generate bins from xmin to xmax if xmax exists,</span>
        <span class="c1"># or just xmin to xmin*1000. This 3 decades is arbitrary, but we</span>
        <span class="c1"># need to make some choice.</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">:</span>
                <span class="n">upper_bound</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="n">upper_bound</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmin</span> <span class="o">*</span> <span class="mf">1e3</span>

            <span class="c1"># 1000 bins is arbitrary.</span>
            <span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">upper_bound</span><span class="p">),</span> <span class="mi">1000</span><span class="p">)</span>

        <span class="n">CCDF</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ccdf</span><span class="p">(</span><span class="n">bins</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">ax</span><span class="p">:</span>
            <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">CCDF</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">CCDF</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="n">ax</span><span class="o">.</span><span class="n">set_xscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_yscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">ax</span></div>



<div class="viewcode-block" id="Distribution.plot_cdf">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Distribution.plot_cdf">[docs]</a>
    <span class="k">def</span> <span class="nf">plot_cdf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Plot the cumulative distribution function (CDF) of the</span>
<span class="sd">        theoretical distribution for the values given in data within ``xmin``</span>
<span class="sd">        and ``xmax``, if present.</span>

<span class="sd">        Plots to a new figure or to axis ``ax`` if provided.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : array_like, optional</span>
<span class="sd">            The data for which to compute the PDF. If not provided, the data</span>
<span class="sd">            passed on creation (if available) will be used.</span>

<span class="sd">        ax : matplotlib axis, optional</span>
<span class="sd">            The axis on which to plot. If None, a new figure is created.</span>

<span class="sd">        kwargs</span>
<span class="sd">            Other keyword arguments are passed to ``matplotlib.pyplot.plot()``.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ax : matplotlib axis</span>
<span class="sd">            The axis on which the plot was made.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># The passed data takes precedence, but otherwise we use the data</span>
        <span class="c1"># stored in the class instance.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">):</span>
            <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span>

        <span class="c1"># If we have data, we use that for the bins</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">):</span>
            <span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">trim_to_range</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">xmin</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">))</span>

        <span class="c1"># Otherwise, we just generate bins from xmin to xmax if xmax exists,</span>
        <span class="c1"># or just xmin to xmin*1000. This 3 decades is arbitrary, but we</span>
        <span class="c1"># need to make some choice.</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">:</span>
                <span class="n">upper_bound</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="n">upper_bound</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmin</span> <span class="o">*</span> <span class="mf">1e3</span>

            <span class="c1"># 1000 bins is arbitrary.</span>
            <span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">upper_bound</span><span class="p">),</span> <span class="mi">1000</span><span class="p">)</span>

        <span class="n">CDF</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">bins</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">ax</span><span class="p">:</span>
            <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">CDF</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">CDF</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="n">ax</span><span class="o">.</span><span class="n">set_xscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_yscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">ax</span></div>



<div class="viewcode-block" id="Distribution.plot_pdf">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Distribution.plot_pdf">[docs]</a>
    <span class="k">def</span> <span class="nf">plot_pdf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Plot the probability density function (PDF) of the</span>
<span class="sd">        theoretical distribution for the values given in data within ``xmin``</span>
<span class="sd">        and ``xmax``, if present.</span>

<span class="sd">        Plots to a new figure or to axis ``ax`` if provided.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : array_like, optional</span>
<span class="sd">            The data for which to compute the PDF. If not provided, the data</span>
<span class="sd">            passed on creation (if available) will be used.</span>

<span class="sd">        ax : matplotlib axis, optional</span>
<span class="sd">            The axis on which to plot. If None, a new figure is created.</span>

<span class="sd">        kwargs</span>
<span class="sd">            Other keyword arguments are passed to `matplotlib.pyplot.plot()`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ax : matplotlib axis</span>
<span class="sd">            The axis to which the plot was made.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># The passed data takes precedence, but otherwise we use the data</span>
        <span class="c1"># stored in the class instance.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">):</span>
            <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span>

        <span class="c1"># If we have data, we use that for the bins</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">):</span>
            <span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">trim_to_range</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">xmin</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">))</span>

        <span class="c1"># Otherwise, we just generate bins from xmin to xmax if xmax exists,</span>
        <span class="c1"># or just xmin to xmin*1000. This 3 decades is arbitrary, but we</span>
        <span class="c1"># need to make some choice.</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">:</span>
                <span class="n">upper_bound</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="n">upper_bound</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmin</span> <span class="o">*</span> <span class="mf">1e3</span>

            <span class="c1"># 1000 bins is arbitrary.</span>
            <span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">upper_bound</span><span class="p">),</span> <span class="mi">1000</span><span class="p">)</span>

        <span class="n">PDF</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">bins</span><span class="p">)</span>

        <span class="c1"># Set to nan so it doesn&#39;t show up on the plot</span>
        <span class="n">PDF</span><span class="p">[</span><span class="n">PDF</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">nan</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">ax</span><span class="p">:</span>
            <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">PDF</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">PDF</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="n">ax</span><span class="o">.</span><span class="n">set_xscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_yscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">ax</span></div>



<div class="viewcode-block" id="Distribution.generate_random">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Distribution.generate_random">[docs]</a>
    <span class="k">def</span> <span class="nf">generate_random</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">estimate_discrete</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generate random numbers from the theoretical probability distribution.</span>

<span class="sd">        This will follow the theoretical distribution, including upper</span>
<span class="sd">        and lower limits defined by ``xmin`` or ``xmax``. For example, if</span>
<span class="sd">        this function is called from a distribution with a finite value of</span>
<span class="sd">        ``xmax``, the generated values will be less than that value. If</span>
<span class="sd">        no value is given for ``xmax``, random values will have no upper</span>
<span class="sd">        limit.</span>

<span class="sd">        For discrete distributions without an approximation method, we</span>
<span class="sd">        use numerical inverse transform sampling.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        size : tuple or int, optional</span>
<span class="sd">            The number of random numbers to generate.</span>

<span class="sd">            If a tuple, will be taken as the shape of the array to generate</span>
<span class="sd">            where each value is randomly generated according to the theoretical</span>
<span class="sd">            distribution.</span>

<span class="sd">        estimate_discrete : bool, optional</span>
<span class="sd">            For discrete distributions, whether to use a faster approximation of</span>
<span class="sd">            the random number generator.</span>

<span class="sd">            If ``None``, attempts to inherit the estimate_discrete behavior used</span>
<span class="sd">            for fitting from the ``Distribution`` object or the parent ``Fit``</span>
<span class="sd">            object, if present. Approximations only exist for some</span>
<span class="sd">            distributions (namely the power law). If an approximation does</span>
<span class="sd">            not exist, an ``estimate_discrete=True`` setting will not be inherited.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        r : array</span>
<span class="sd">            Random numbers drawn from the distribution with shape equal</span>
<span class="sd">            to ``size``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># For generating uniform random numbers from ~0 to ~1</span>
        <span class="c1"># We shouldn&#39;t actually start from 0, but from _cdf_xmin, which should</span>
        <span class="c1"># be very close to zero.</span>
        <span class="c1"># If we have an xmax, we shouldn&#39;t use 1 as the upper bound, but</span>
        <span class="c1"># cdf(xmax). Note that this only works for when we use the continuous</span>
        <span class="c1"># method (either continuous data or discrete data but we don&#39;t use</span>
        <span class="c1"># the approximate discrete method). For the approximated discrete</span>
        <span class="c1"># case, we have to calculate a different upper limit (see below).</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">:</span>
            <span class="n">upper_bound</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cdf_base_function</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">upper_bound</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="c1"># For continuous random numbers we usually don&#39;t need to do any</span>
        <span class="c1"># approximations, and can just transform according to the specific</span>
        <span class="c1"># distribution.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">discrete</span><span class="p">:</span>
            <span class="n">uniform_r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cdf_xmin</span><span class="p">,</span> <span class="n">upper_bound</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">)</span>
            <span class="n">r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_random_continuous</span><span class="p">(</span><span class="n">uniform_r</span><span class="p">)</span>

        <span class="c1"># For discrete distributions, we usually have to make some</span>
        <span class="c1"># approximation.</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Make sure that this distribution supports approximating the</span>
            <span class="c1"># continuous distribution with some discrete scheme.</span>
            <span class="k">if</span> <span class="n">estimate_discrete</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_generate_random_discrete_estimate&#39;</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s2">&quot;This distribution does not have an estimation of the discrete form for </span><span class="se">\</span>
<span class="s2">                                     generating simulated data. Try the exact form with estimate_discrete=False.&quot;</span><span class="p">)</span>

            <span class="c1"># If no value for estimate discrete is given, we should decide</span>
            <span class="c1"># based on whether the distribution is first able to do this</span>
            <span class="c1"># at all, then whether the class has already been passed a</span>
            <span class="c1"># value on creation.</span>
            <span class="k">if</span> <span class="n">estimate_discrete</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                
                <span class="c1"># We can&#39;t estimate discrete is there isn&#39;t a function</span>
                <span class="c1"># for it.</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_generate_random_discrete_estimate&#39;</span><span class="p">):</span>
                    <span class="n">estimate_discrete</span> <span class="o">=</span> <span class="kc">False</span>

                <span class="c1"># Check the value of self.estimate_discrete.</span>
                <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;estimate_discrete&#39;</span><span class="p">):</span>
                    <span class="n">estimate_discrete</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimate_discrete</span>

                <span class="c1"># Check the value of estimate_discrete for the parent object.</span>
                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent_Fit</span><span class="p">:</span>
                    <span class="n">estimate_discrete</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent_Fit</span><span class="o">.</span><span class="n">estimate_discrete</span>

                <span class="c1"># If none of those worked, don&#39;t estimate.</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">estimate_discrete</span> <span class="o">=</span> <span class="kc">False</span>


            <span class="c1"># Use the approximation method if it&#39;s available and</span>
            <span class="c1"># desired.</span>
            <span class="k">if</span> <span class="n">estimate_discrete</span><span class="p">:</span>
                <span class="c1"># Note that if we use the approximate discrete method, the</span>
                <span class="c1"># upper bound is different, since we are using a different</span>
                <span class="c1"># function than _cdf_base_function.</span>
                <span class="c1"># So we first do a search to find the maximum value, ie.</span>
                <span class="c1"># the r value such that _generate_random_discrete_estimate(r) = xmax</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">:</span>
                    <span class="n">upper_bound</span> <span class="o">=</span> <span class="n">bisect_map</span><span class="p">(</span><span class="n">mn</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">mx</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                             <span class="n">function</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_generate_random_discrete_estimate</span><span class="p">,</span>
                                             <span class="n">target</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">xmax</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="c1"># -1 to make sure we always generate values under xmax</span>
                                             <span class="n">tol</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">)</span>

                <span class="n">uniform_r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">upper_bound</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">)</span>

                <span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_generate_random_discrete_estimate</span><span class="p">(</span><span class="n">uniform_r</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># For each of the uniform values (r), we do the</span>
                <span class="c1"># inverse search problem to find the specific value of x</span>
                <span class="c1"># where the ccdf is equal to that value of r. The x value</span>
                <span class="c1"># is then the random value we return.</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">upper_bound</span><span class="p">)</span>
                <span class="n">uniform_r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">upper_bound</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">)</span>
                <span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">_double_search_discrete</span><span class="p">(</span><span class="n">R</span><span class="p">)</span> <span class="k">for</span> <span class="n">R</span> <span class="ow">in</span> <span class="n">uniform_r</span><span class="o">.</span><span class="n">flatten</span><span class="p">()],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>

                <span class="c1"># Now reshape</span>
                <span class="n">r</span> <span class="o">=</span> <span class="n">r</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">r</span></div>



<div class="viewcode-block" id="Distribution._double_search_discrete">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Distribution._double_search_discrete">[docs]</a>
    <span class="k">def</span> <span class="nf">_double_search_discrete</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">r</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform the inverse search problem of locating the x value</span>
<span class="sd">        such that ccdf(x) = 1 - r.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        r : float in [0, 1]</span>
<span class="sd">            A uniform random variable.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        x : float</span>
<span class="sd">            The sampled value from the theoretical distribution.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Find a range [x1, x2] that contains our random probability r</span>
        <span class="n">x2</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="p">)</span>
        <span class="k">while</span> <span class="bp">self</span><span class="o">.</span><span class="n">ccdf</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">[</span><span class="n">x2</span><span class="p">])</span> <span class="o">&gt;=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">r</span><span class="p">):</span>
            <span class="n">x1</span> <span class="o">=</span> <span class="n">x2</span>
            <span class="n">x2</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">x1</span>

            <span class="c1"># Make sure to clip the bound by xmax</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span> <span class="ow">and</span> <span class="n">x2</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">:</span>
                <span class="n">x2</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">)</span>
                <span class="c1"># And end, since we can&#39;t go higher anymore</span>
                <span class="k">break</span>

        <span class="c1"># Use binary search within that range to find the integer that gives</span>
        <span class="c1"># a ccdf value closest to the desired r (or rather, 1 - r).</span>
        <span class="c1"># up to the limit of being between two integers.</span>
        <span class="n">func</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">ccdf</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">bisect_map</span><span class="p">(</span><span class="n">mn</span><span class="o">=</span><span class="n">x1</span><span class="p">,</span> <span class="n">mx</span><span class="o">=</span><span class="n">x2</span><span class="p">,</span> <span class="n">function</span><span class="o">=</span><span class="n">func</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="mi">1</span><span class="o">-</span><span class="n">r</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">around</span><span class="p">(</span><span class="n">x</span><span class="p">))</span></div>
</div>



<div class="viewcode-block" id="Power_Law">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Power_Law">[docs]</a>
<span class="k">class</span> <span class="nc">Power_Law</span><span class="p">(</span><span class="n">Distribution</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A power law distribution, :math:`p(x) \sim x^{-\alpha}`.</span>

<span class="sd">    The exponent :math:`\alpha` should be positive, and is typically in the</span>
<span class="sd">    range :math:`(1, 3]`. For a normalizable distribution on an infinite or</span>
<span class="sd">    semi-infinite domain (ie. no :math:`x_{max}`), we should have alpha greater</span>
<span class="sd">    than 1.</span>

<span class="sd">    For continuous power laws with :math:`\alpha \in (1, 3]`, there is an</span>
<span class="sd">    exact expression for the maximum likelihood estimation (MLE) to a set of data [1].</span>
<span class="sd">    As such, numerical fitting is only performed when this expression isn&#39;t</span>
<span class="sd">    available, ie. when:</span>

<span class="sd">    1. The :math:`\alpha` value from this expression is less than 1 or</span>
<span class="sd">    greater than 3, indicating that the true :math:`\alpha` may be outside</span>
<span class="sd">    this range, or,</span>
<span class="sd">    2. There is a finite value for :math:`x_{max}`.</span>

<span class="sd">    For discrete power laws, there is an approximate expression for the</span>
<span class="sd">    :math:`\alpha` value from the MLE that is used under the following</span>
<span class="sd">    conditions:</span>

<span class="sd">    1. There is no value for :math:`x_{max}`,</span>
<span class="sd">    2. :math:`x_{min}` is greater than or equal to 10,</span>
<span class="sd">    3. The true alpha value of the distribution is in the range :math:`(1, 3]`, and</span>
<span class="sd">    4. The value from this expression falls in the range :math:`(1, 3]`.</span>

<span class="sd">    You can disable the use of this approximate expression with</span>
<span class="sd">    ``estimate_discrete=False``. These same considerations apply to the</span>
<span class="sd">    approximation discrete random number generator, which is also controlled</span>
<span class="sd">    using the same keyword.</span>

<span class="sd">    If you would like to perform numerical fitting after initializing</span>
<span class="sd">    the values with these above expressions --- in case you are worried</span>
<span class="sd">    they aren&#39;t good approximations for some particular case --- you can</span>
<span class="sd">    force this with ``force_numerical_fit=True``.</span>

<span class="sd">    Accepts all kwargs from ``Distribution`` super class.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;power_law&#39;</span>

    <span class="n">parameter_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;alpha&#39;</span><span class="p">]</span>

    <span class="n">DEFAULT_PARAMETER_RANGES</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">]}</span>


    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">estimate_discrete</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">force_numerical_fit</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        estimate_discrete : bool, optional</span>
<span class="sd">            Whether to estimate alpha for discrete distributions using the</span>
<span class="sd">            approximate method described in [1].</span>

<span class="sd">            By default, this will be enabled when the error is of order 1%</span>
<span class="sd">            or less: according to the original paper, this is when there is</span>
<span class="sd">            no ``xmax`` and ``xmin &lt;= 10``. Otherwise it will be disabled.</span>

<span class="sd">            Set this value to True or False to force the approximation to</span>
<span class="sd">            be used or not.</span>

<span class="sd">        force_numerical_fit : bool, optional</span>
<span class="sd">            Whether to force the fitting process to include numerical fitting</span>
<span class="sd">            even if an analytic expression is available. In this case, the</span>
<span class="sd">            result of the analytic expression will be used as the initial</span>
<span class="sd">            guess for the numerical fitting.</span>

<span class="sd">            See the documentation on this class for more information on</span>
<span class="sd">            when analytical or numerical fitting is used.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># This value will be parsed (and auto assigned if None) in</span>
        <span class="c1"># generate_initial_parameters.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">estimate_discrete</span> <span class="o">=</span> <span class="n">estimate_discrete</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">force_numerical_fit</span> <span class="o">=</span> <span class="n">force_numerical_fit</span>

        <span class="n">Distribution</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># We also might want to warn if we have an unbounded power law (no</span>
        <span class="c1"># xmax) with an exponent less than 1.1, since things start to</span>
        <span class="c1"># get very messy around there.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">&lt;=</span> <span class="mf">1.1</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;Power law distributions with alpha close to 1 without an xmax can be very noisy; it is recommended to give some xmax.&#39;</span><span class="p">)</span>


<div class="viewcode-block" id="Power_Law.generate_initial_parameters">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Power_Law.generate_initial_parameters">[docs]</a>
    <span class="k">def</span> <span class="nf">generate_initial_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generate initial guesses for the distribution parameters based</span>
<span class="sd">        on the data.</span>

<span class="sd">        For continuous distributions, we use the following value to estimate</span>
<span class="sd">        :math:`\alpha` (see Clauset et al. (2009) [1], Eq. 3.1). In the limit as N</span>
<span class="sd">        goes to infinity, this becomes the exact solution to the maximum</span>
<span class="sd">        likelihood estimation problem. Generally this is a very good</span>
<span class="sd">        estimation even at modest values (~1000) of N as well.</span>

<span class="sd">            $$ \alpha_0 = 1 + N / ( \sum \log (x / x_{min})) $$</span>

<span class="sd">        For the discrete case, there is no form that is exact in the large</span>
<span class="sd">        N limit, but the following value is a good approximation when</span>
<span class="sd">        there is no ``xmax`` and ``xmin &gt;= 10`` (see ref [1], Eq. 3.7).</span>

<span class="sd">            $$ \alpha_0 = 1 + N / ( \sum \log (x / (x_{min} - 1/2))) $$</span>


<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : array_like</span>
<span class="sd">            The data to use to generate the initial values of parameters.</span>

<span class="sd">            Should already be trimmed to the data range defined by</span>
<span class="sd">            `xmin` and `xmax` (if included).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        params : dict</span>
<span class="sd">            A dictionary of the parameters and their values.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        [1] Clauset, A., Shalizi, C. R., &amp; Newman, M. E. J. (2009).</span>
<span class="sd">        Power-law distributions in empirical data. SIAM Review, 51(4),</span>
<span class="sd">        661–703. https://doi.org/10.1137/070710111</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># If estimate_discrete is None, we decied whether to use it based</span>
        <span class="c1"># xmin and xmax values.</span>
        <span class="c1"># (we can&#39;t put this in __init__ because xmin and xmax aren&#39;t</span>
        <span class="c1"># defined yet)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimate_discrete</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">estimate_discrete</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xmin</span> <span class="o">&gt;=</span> <span class="mi">10</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xmax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">discrete</span>

        <span class="c1"># Also give a warning if estimate discrete is true but xmin is small</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimate_discrete</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xmin</span> <span class="o">&lt;=</span> <span class="mi">6</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">discrete</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;estimate_discrete=True but xmin is quite small (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="si">}</span><span class="s1">). This may give inaccurate results.&#39;</span><span class="p">)</span>

        <span class="n">params</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># This is generally a very good approximation of the power law</span>
        <span class="c1"># exponent for alpha &gt; 1. For values of alpha &lt; 1, it will only</span>
        <span class="c1"># approach 1, as expected from the 1 + ...</span>

        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="c1"># If we have a discrete distribution (ie only takes on integer</span>
        <span class="c1"># values) we have to shift slightly.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">discrete</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimate_discrete</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">:</span>
            <span class="n">params</span><span class="p">[</span><span class="s2">&quot;alpha&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">n</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">data</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xmin</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)))</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># For continuous, we just have the usual expression.</span>
            <span class="n">params</span><span class="p">[</span><span class="s2">&quot;alpha&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">n</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">data</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="p">)))</span>

        <span class="c1"># If we have some non-clean distributions (eg. a flat distribution that</span>
        <span class="c1"># then becomes power law at some xmin), the estimate above</span>
        <span class="c1"># could be less than 1 or even negative. It&#39;s better to just</span>
        <span class="c1"># start the fitting at 1 instead in those cases.</span>
        <span class="k">if</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;alpha&quot;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">params</span><span class="p">[</span><span class="s2">&quot;alpha&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="k">return</span> <span class="n">params</span></div>



<div class="viewcode-block" id="Power_Law.fit">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Power_Law.fit">[docs]</a>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fits the parameters of the distribution to the data.</span>

<span class="sd">        Overloaded from ``Distribution`` version since we may want to</span>
<span class="sd">        use the analytic expression for the maximum likihood estimation</span>
<span class="sd">        of :math:`\alpha` instead of numerically fitting.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># The generate_initial_parameters() function has already been</span>
        <span class="c1"># called by the time this is called, so the value of self.alpha</span>
        <span class="c1"># will already be set using the appropriate analytical expression.</span>

        <span class="c1"># Wherever we don&#39;t call Distribution.fit(), we need to call</span>
        <span class="c1"># compute_distance_metrics(), since this is normally done</span>
        <span class="c1"># at the end of the super class fit().</span>

        <span class="c1"># If the user has specifically requested that a numerical fit is</span>
        <span class="c1"># performed (using the analytical expressions as initial guesses)</span>
        <span class="c1"># then we just call the super method. The analytical methods are</span>
        <span class="c1"># already used in ``generate_initial_parameters()``, so this will</span>
        <span class="c1"># use those as an initial guess.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">force_numerical_fit</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">Distribution</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
           
        <span class="c1"># The condition for the below two to be used is that the alpha</span>
        <span class="c1"># value (the true one) is within (1, 3]. That being said, the</span>
        <span class="c1"># estimations in generate_initial_parameters will give alpha</span>
        <span class="c1"># values of [1, 1.15] for power laws that actually have an alpha</span>
        <span class="c1"># &lt; 1. So we should run the numerical fitting just in case even</span>
        <span class="c1"># if the alpha is above one, up to about 1.5 or so. By setting this</span>
        <span class="c1"># cutoff higher, we only lose a bit of speed, but setting it too</span>
        <span class="c1"># low can give inaccurate results without warning, so better to be</span>
        <span class="c1"># conservative here.</span>

        <span class="c1"># If we want to use the discrete estimation and the initial</span>
        <span class="c1"># guess is within (1.5, 3], we skip numerical fitting.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">discrete</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimate_discrete</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">&gt;</span> <span class="mf">1.5</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">&lt;=</span> <span class="mi">3</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">compute_distance_metrics</span><span class="p">()</span>
            <span class="k">return</span>

        <span class="c1"># If we want to use the continuous estimation and the initial</span>
        <span class="c1"># guess is within  (1.5, 3], we skip numerical fitting.</span>
        <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">discrete</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">&gt;</span> <span class="mf">1.5</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">&lt;=</span> <span class="mi">3</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">compute_distance_metrics</span><span class="p">()</span>
            <span class="k">return</span>

        <span class="c1"># Otherwise we run the numerical fitting</span>
        <span class="k">return</span> <span class="n">Distribution</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span></div>



    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">sigma</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The standard error of the MLE.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Only is calculable after self.fit is started, when the number of data points is</span>
        <span class="c1"># established</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">)</span>


<div class="viewcode-block" id="Power_Law._cdf_base_function">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Power_Law._cdf_base_function">[docs]</a>
    <span class="k">def</span> <span class="nf">_cdf_base_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">discrete</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">scipy.special</span> <span class="kn">import</span> <span class="n">zeta</span>
            <span class="n">CDF</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">zeta</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1">#Can this be reformulated to not reference xmin? Removal of the probability</span>
            <span class="c1">#before xmin and after xmax is handled in Distribution.cdf(), so we don&#39;t</span>
            <span class="c1">#strictly need this element. It doesn&#39;t hurt, for the moment.</span>
            <span class="n">CDF</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">x</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">CDF</span></div>



<div class="viewcode-block" id="Power_Law._pdf_base_function">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Power_Law._pdf_base_function">[docs]</a>
    <span class="k">def</span> <span class="nf">_pdf_base_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">x</span><span class="o">**</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span></div>



    <span class="c1"># TODO: This function sometimes gives its warning during the fitting</span>
    <span class="c1"># process, and then the final fit ends up being &gt; 1, so it looks like</span>
    <span class="c1"># it raised the warning incorrectly. Maybe there is some way to clean</span>
    <span class="c1"># up when this is shown or not.</span>
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_pdf_continuous_normalizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># The pdf has a different form when we consider xmax as</span>
        <span class="c1"># the upper limit of the distribution. When alpha &lt; 1, we have to</span>
        <span class="c1"># assume the distribution ends at xmax otherwise it is not</span>
        <span class="c1"># normalizable.</span>
        <span class="n">xmax</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">:</span>
            <span class="n">xmax</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="c1"># If we have data available, we should use the maximum value and warn.</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">):</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;Distribution with alpha &lt;= 1 has no xmax; setting xmax to be max(data) otherwise cannot continue. Consider setting an explicit value for xmax&#39;</span><span class="p">)</span>

                        <span class="n">xmax</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

                <span class="c1"># Otherwise, we need to raise an error, since we cant have</span>
                <span class="c1"># a distribution with alpha &lt;= 1, no xmax, and no data to</span>
                <span class="c1"># infer an xmax from.</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Power law distribution with alpha &lt;= 1 must have an xmax or at least data to infer an implicit xmax from.&#39;</span><span class="p">)</span>


        <span class="k">if</span> <span class="n">xmax</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">xmax</span><span class="o">**</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="o">**</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="o">**</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>


    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_pdf_discrete_normalizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">C</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cdf_xmin</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">:</span>
            <span class="n">C</span> <span class="o">-=</span> <span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cdf_base_function</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">C</span> <span class="o">=</span> <span class="mf">1.0</span><span class="o">/</span><span class="n">C</span>
        <span class="k">return</span> <span class="n">C</span>

<div class="viewcode-block" id="Power_Law._generate_random_continuous">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Power_Law._generate_random_continuous">[docs]</a>
    <span class="k">def</span> <span class="nf">_generate_random_continuous</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">r</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmin</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">r</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span></div>



<div class="viewcode-block" id="Power_Law._generate_random_discrete_estimate">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Power_Law._generate_random_discrete_estimate">[docs]</a>
    <span class="k">def</span> <span class="nf">_generate_random_discrete_estimate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">r</span><span class="p">):</span>
        <span class="c1"># This estimation only works for alpha &gt; 1</span>
        <span class="c1"># So even if we explicitly pass estimate_discrete=True, we can&#39;t</span>
        <span class="c1"># use this when alpha &lt;= 1.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Discrete power law random generator estimation only works for alpha &gt; 1! Use estimate_discrete=False.&#39;</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xmin</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">r</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span> <span class="o">+</span> <span class="mf">0.5</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">around</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></div>
</div>



<div class="viewcode-block" id="Exponential">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Exponential">[docs]</a>
<span class="k">class</span> <span class="nc">Exponential</span><span class="p">(</span><span class="n">Distribution</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    An exponential distribution :math:`p(x) \sim e^{- \lambda x}`.</span>

<span class="sd">    For expressions for normalization for discrete and continuous</span>
<span class="sd">    distributions, see Clauset et al. (2009) [1], Table 2.1.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    [1] Clauset, A., Shalizi, C. R., &amp; Newman, M. E. J. (2009).</span>
<span class="sd">    Power-law distributions in empirical data. SIAM Review, 51(4),</span>
<span class="sd">    661–703. https://doi.org/10.1137/070710111</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;exponential&#39;</span>

    <span class="c1"># Note that Lambda has a capital L; I guess this is because</span>
    <span class="c1"># the authors didn&#39;t want to cause confusion with Python&#39;s lambda</span>
    <span class="c1"># expressions.</span>
    <span class="n">parameter_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Lambda&#39;</span><span class="p">]</span>

    <span class="n">DEFAULT_PARAMETER_RANGES</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Lambda&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">]}</span>


<div class="viewcode-block" id="Exponential.generate_initial_parameters">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Exponential.generate_initial_parameters">[docs]</a>
    <span class="k">def</span> <span class="nf">generate_initial_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        For an exponential distribution, we estimate the exponent factor</span>
<span class="sd">        as:</span>
<span class="sd">            $$ \lambda_0 = 1 / mean(x) $$</span>


<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : array_like</span>
<span class="sd">            The data to use to generate the initial values of parameters.</span>

<span class="sd">            Should already be trimmed to the data range defined by</span>
<span class="sd">            `xmin` and `xmax` (if included).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        params : dict</span>
<span class="sd">            A dictionary of the parameters and their values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">params</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="n">params</span><span class="p">[</span><span class="s2">&quot;Lambda&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">params</span></div>



<div class="viewcode-block" id="Exponential._cdf_base_function">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Exponential._cdf_base_function">[docs]</a>
    <span class="k">def</span> <span class="nf">_cdf_base_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The cumulative distribution function for an exponential distribution</span>
<span class="sd">        is:</span>
<span class="sd">            $$ c(x) ~ 1 - exp(-\lambda x) $$</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">Lambda</span><span class="o">*</span><span class="n">x</span><span class="p">)</span></div>



<div class="viewcode-block" id="Exponential._pdf_base_function">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Exponential._pdf_base_function">[docs]</a>
    <span class="k">def</span> <span class="nf">_pdf_base_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The probability distribution function for an exponential distribution</span>
<span class="sd">        is:</span>
<span class="sd">            $$ p(x) ~ exp(-\lambda x) $$</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">Lambda</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span></div>



    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_pdf_continuous_normalizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># We could put an expression including xmax here but it probably</span>
        <span class="c1"># wouldn&#39;t make much of a difference.</span>
        
        <span class="c1"># There&#39;s a reasonable chance this line can lead to overflow errors</span>
        <span class="c1"># since it is a positive exponential with what could be a large</span>
        <span class="c1"># number. The end calculation would theoretically be fine since</span>
        <span class="c1"># the x values will always be &gt; xmin, and therefore we will also</span>
        <span class="c1"># have a tiny _pdf_base_function value.</span>

        <span class="c1"># But in order to store this value in the meantime, we have to</span>
        <span class="c1"># use a float128 type. The ideal solution might be to use a proper</span>
        <span class="c1"># infinite precision module like mpmath or decimal, but I think</span>
        <span class="c1"># this should work for all cases.</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Lambda</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float128</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Lambda</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="p">))</span>


    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_pdf_discrete_normalizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Note that we use float128 (long double) here since otherwise</span>
        <span class="c1"># we might get an overflow error. See _pdf_continuous_normalizer</span>
        <span class="c1"># for full discussion.</span>
        <span class="n">C</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">Lambda</span><span class="p">))</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float128</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Lambda</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="p">))</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">:</span>
            <span class="n">Cxmax</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">Lambda</span><span class="p">))</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float128</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Lambda</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">))</span>
            <span class="n">C</span> <span class="o">=</span> <span class="mf">1.0</span><span class="o">/</span><span class="n">C</span> <span class="o">-</span> <span class="mf">1.0</span><span class="o">/</span><span class="n">Cxmax</span>
            <span class="n">C</span> <span class="o">=</span> <span class="mf">1.0</span><span class="o">/</span><span class="n">C</span>

        <span class="k">return</span> <span class="n">C</span>


    <span class="c1"># This function used to overload the pdf() defined in the super class</span>
    <span class="c1"># but it doesn&#39;t seem to do anything different...?</span>
    <span class="c1"># If the if condition evaluates true, then it just calculated the</span>
    <span class="c1"># likelihood as _pdf_base_function(x) * _pdf_continuous_normalizer,</span>
    <span class="c1"># which is exactly what the parent pdf() does.</span>
<span class="c1">#    def pdf(self, data=None):</span>
<span class="c1">#        if data is None and self.parent_Fit:</span>
<span class="c1">#            data = self.parent_Fit.data</span>
<span class="c1">#</span>
<span class="c1">#        if not self.discrete and self.in_range() and not self.xmax:</span>
<span class="c1">#            print(&#39;special pdf2&#39;)</span>
<span class="c1">#            data = trim_to_range(data, xmin=self.xmin, xmax=self.xmax)</span>
<span class="c1">#            from numpy import exp</span>
<span class="c1">#        likelihoods = exp(-Lambda*data)*\</span>
<span class="c1">#                Lambda*exp(Lambda*xmin)</span>
<span class="c1">#</span>
<span class="c1">#            # This is _pdf_base_function(x) * _pdf_continuous_normalizer(xmin)</span>
<span class="c1">#            likelihoods = self.Lambda*exp(self.Lambda*(self.xmin-data))</span>
<span class="c1">#</span>
<span class="c1">#            #Simplified so as not to throw a nan from infs being divided by each other</span>
<span class="c1">#            from sys import float_info</span>
<span class="c1">#            likelihoods[likelihoods==0] = 10**float_info.min_10_exp</span>
<span class="c1">#</span>
<span class="c1">#        else:</span>
<span class="c1">#            likelihoods = Distribution.pdf(self, data)</span>
<span class="c1">#</span>
<span class="c1">#        return likelihoods</span>
<span class="c1">#</span>
<span class="c1">#    def loglikelihoods(self, data=None):</span>
<span class="c1">#        if data is None and self.parent_Fit:</span>
<span class="c1">#            data = self.parent_Fit.data</span>
<span class="c1">#</span>
<span class="c1">#        if not self.discrete and self.in_range() and not self.xmax:</span>
<span class="c1">#            data = trim_to_range(data, xmin=self.xmin, xmax=self.xmax)</span>
<span class="c1">#            from numpy import log</span>
<span class="c1">#        likelihoods = exp(-Lambda*data)*\</span>
<span class="c1">#                Lambda*exp(Lambda*xmin)</span>
<span class="c1">#            loglikelihoods = log(self.Lambda) + (self.Lambda*(self.xmin-data))</span>
<span class="c1">#            #Simplified so as not to throw a nan from infs being divided by each other</span>
<span class="c1">#            from sys import float_info</span>
<span class="c1">#            loglikelihoods[loglikelihoods==0] = log(10**float_info.min_10_exp)</span>
<span class="c1">#        else:</span>
<span class="c1">#            loglikelihoods = Distribution.loglikelihoods(self, data)</span>
<span class="c1">#        return loglikelihoods</span>


<div class="viewcode-block" id="Exponential._generate_random_continuous">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Exponential._generate_random_continuous">[docs]</a>
    <span class="k">def</span> <span class="nf">_generate_random_continuous</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">r</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmin</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">Lambda</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">r</span><span class="p">)</span></div>
</div>



<div class="viewcode-block" id="Stretched_Exponential">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Stretched_Exponential">[docs]</a>
<span class="k">class</span> <span class="nc">Stretched_Exponential</span><span class="p">(</span><span class="n">Distribution</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A stretched exponential distribution, :math:`p(x) \sim (x \lambda)^{\beta - 1}</span>
<span class="sd">    e^{- (\lambda x)^\beta}`.</span>

<span class="sd">    For expressions for normalization for discrete and continuous</span>
<span class="sd">    distributions, see Clauset et al. (2009) [1], Table 2.1.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    [1] Clauset, A., Shalizi, C. R., &amp; Newman, M. E. J. (2009).</span>
<span class="sd">    Power-law distributions in empirical data. SIAM Review, 51(4),</span>
<span class="sd">    661–703. https://doi.org/10.1137/070710111</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Note that Lambda has a capital L; I guess this is because</span>
    <span class="c1"># the authors didn&#39;t want to cause confusion with Python&#39;s lambda</span>
    <span class="c1"># expressions.</span>
    <span class="c1"># That being said, the old code had:</span>
    <span class="c1"># self.parameter1 = self.Lambda</span>
    <span class="c1"># self.parameter1_name = &#39;lambda&#39;</span>
    <span class="c1"># Which is inconsistent; I&#39;ve chosen the capital lambda so far,</span>
    <span class="c1"># but should look into making this more consistent later. TODO</span>

    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;stretched_exponential&#39;</span>

    <span class="n">parameter_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Lambda&#39;</span><span class="p">,</span> <span class="s1">&#39;beta&#39;</span><span class="p">]</span>

    <span class="n">DEFAULT_PARAMETER_RANGES</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Lambda&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
                                <span class="s1">&#39;beta&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">]}</span>


<div class="viewcode-block" id="Stretched_Exponential.generate_initial_parameters">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Stretched_Exponential.generate_initial_parameters">[docs]</a>
    <span class="k">def</span> <span class="nf">generate_initial_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        For an exponential distribution, we estimate the exponent factor</span>
<span class="sd">        as:</span>
<span class="sd">            $$ \lambda_0 = 1 / mean(x) $$</span>

<span class="sd">        The stretch exponent $\beta$ just starts with a value $1$.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : array_like</span>
<span class="sd">            The data to use to generate the initial values of parameters.</span>

<span class="sd">            Should already be trimmed to the data range defined by</span>
<span class="sd">            `xmin` and `xmax` (if included).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        params : dict</span>
<span class="sd">            A dictionary of the parameters and their values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">params</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="n">params</span><span class="p">[</span><span class="s2">&quot;Lambda&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">params</span><span class="p">[</span><span class="s2">&quot;beta&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="k">return</span> <span class="n">params</span></div>



<div class="viewcode-block" id="Stretched_Exponential._cdf_base_function">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Stretched_Exponential._cdf_base_function">[docs]</a>
    <span class="k">def</span> <span class="nf">_cdf_base_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">CDF</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Lambda</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">CDF</span></div>



<div class="viewcode-block" id="Stretched_Exponential._pdf_base_function">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Stretched_Exponential._pdf_base_function">[docs]</a>
    <span class="k">def</span> <span class="nf">_pdf_base_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># TODO: This is different from the base function defined in Clauset</span>
        <span class="c1"># et al. 2009. It has extra factors of lambda and exp(lambda^beta)</span>
        <span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">exp</span>
        <span class="k">return</span> <span class="p">(((</span><span class="n">x</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">Lambda</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">*</span>
                <span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">Lambda</span><span class="o">*</span><span class="n">x</span><span class="p">)</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)))</span></div>



    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_pdf_continuous_normalizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Same issue here as with Exponential; we could get an overflow</span>
        <span class="c1"># error since this value might be very large, so we use float128.</span>
        <span class="n">C</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">Lambda</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float128</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Lambda</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="p">)</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">C</span>


    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_pdf_discrete_normalizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">False</span>


    <span class="c1"># These are deprecated and do nothing different than the super</span>
    <span class="c1"># implementation in Distribution</span>
<span class="c1">#    def pdf(self, data=None):</span>
<span class="c1">#        if data is None and self.parent_Fit:</span>
<span class="c1">#            data = self.parent_Fit.data</span>
<span class="c1">#</span>
<span class="c1">#        if not self.discrete and self.in_range() and not self.xmax:</span>
<span class="c1">#            data = trim_to_range(data, xmin=self.xmin, xmax=self.xmax)</span>
<span class="c1">#            from numpy import exp</span>
<span class="c1">#            likelihoods = ((data*self.Lambda)**(self.beta-1) *</span>
<span class="c1">#                           self.beta * self.Lambda *</span>
<span class="c1">#                           exp((self.Lambda*self.xmin)**self.beta -</span>
<span class="c1">#                               (self.Lambda*data)**self.beta))</span>
<span class="c1">#            #Simplified so as not to throw a nan from infs being divided by each other</span>
<span class="c1">#            from sys import float_info</span>
<span class="c1">#            likelihoods[likelihoods==0] = 10**float_info.min_10_exp</span>
<span class="c1">#        else:</span>
<span class="c1">#            likelihoods = Distribution.pdf(self, data)</span>
<span class="c1">#        return likelihoods</span>
<span class="c1">#</span>
<span class="c1">#    def loglikelihoods(self, data=None):</span>
<span class="c1">#        if data is None and self.parent_Fit:</span>
<span class="c1">#            data = self.parent_Fit.data</span>
<span class="c1">#</span>
<span class="c1">#        if not self.discrete and self.in_range() and not self.xmax:</span>
<span class="c1">#            data = trim_to_range(data, xmin=self.xmin, xmax=self.xmax)</span>
<span class="c1">#            from numpy import log</span>
<span class="c1">#            loglikelihoods = (</span>
<span class="c1">#                    log((data*self.Lambda)**(self.beta-1) *</span>
<span class="c1">#                        self.beta * self. Lambda) +</span>
<span class="c1">#                    (self.Lambda*self.xmin)**self.beta -</span>
<span class="c1">#                        (self.Lambda*data)**self.beta)</span>
<span class="c1">#            #Simplified so as not to throw a nan from infs being divided by each other</span>
<span class="c1">#            from sys import float_info</span>
<span class="c1">#            from numpy import inf</span>
<span class="c1">#            loglikelihoods[loglikelihoods==-inf] = log(10**float_info.min_10_exp)</span>
<span class="c1">#        else:</span>
<span class="c1">#            loglikelihoods = Distribution.loglikelihoods(self, data)</span>
<span class="c1">#        return loglikelihoods</span>

<div class="viewcode-block" id="Stretched_Exponential._generate_random_continuous">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Stretched_Exponential._generate_random_continuous">[docs]</a>
    <span class="k">def</span> <span class="nf">_generate_random_continuous</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">r</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">log</span>
<span class="c1">#        return ( (self.xmin**self.beta) -</span>
<span class="c1">#            (1/self.Lambda) * log(1-r) )**(1/self.beta)</span>
        <span class="k">return</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">Lambda</span><span class="p">)</span><span class="o">*</span> <span class="p">(</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Lambda</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="p">)</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">-</span>
            <span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">r</span><span class="p">)</span> <span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span></div>
</div>



<div class="viewcode-block" id="Truncated_Power_Law">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Truncated_Power_Law">[docs]</a>
<span class="k">class</span> <span class="nc">Truncated_Power_Law</span><span class="p">(</span><span class="n">Distribution</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A power law distribution truncated by an exponential, :math:`p(x) \sim</span>
<span class="sd">    x^{-\alpha} e^{-\lambda x}`.</span>

<span class="sd">    The exponent :math:`\alpha` should be positive, though can have any</span>
<span class="sd">    positive value and still be normalizable. Unlike a true power law,</span>
<span class="sd">    there is no trouble having :math:`\alpha \le 1`, since the</span>
<span class="sd">    exponential tail ensures that the distribution is always normalizable.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;truncated_power_law&#39;</span>

    <span class="n">parameter_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;alpha&#39;</span><span class="p">,</span> <span class="s1">&#39;Lambda&#39;</span><span class="p">]</span>

    <span class="n">DEFAULT_PARAMETER_RANGES</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
                                <span class="s1">&#39;Lambda&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">]}</span>


<div class="viewcode-block" id="Truncated_Power_Law.generate_initial_parameters">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Truncated_Power_Law.generate_initial_parameters">[docs]</a>
    <span class="k">def</span> <span class="nf">generate_initial_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generate initial guesses for the distribution parameters based</span>
<span class="sd">        on the data.</span>

<span class="sd">        For continuous distributions, we use the following value to estimate</span>
<span class="sd">        alpha (see Clauset et al. (2009) [1], Eq. 3.1). In the limit as N goes to infinity,</span>
<span class="sd">        this becomes exact, and generally is a very good estimation even</span>
<span class="sd">        at modest values (~1000) of N.</span>

<span class="sd">            $$ \alpha_0 = 1 + N / ( \sum \log (x / x_{min})) $$</span>

<span class="sd">        For the discrete case, there is no form that is exact in the large</span>
<span class="sd">        N limit, but the following value is a good approximation (see ref</span>
<span class="sd">        [1], Eq. 3.7).</span>

<span class="sd">            $$ \alpha_0 = 1 + N / ( \sum \log (x / (x_{min} - 1/2))) $$</span>

<span class="sd">        As with the exponential distribution, lambda is taken as the inverse</span>
<span class="sd">        of the mean of the data:</span>

<span class="sd">            $$ \lambda_0 = 1 / mean(x) $$</span>


<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : array_like</span>
<span class="sd">            The data to use to generate the initial values of parameters.</span>

<span class="sd">            Should already be trimmed to the data range defined by</span>
<span class="sd">            `xmin` and `xmax` (if included).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        params : dict</span>
<span class="sd">            A dictionary of the parameters and their values.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        [1] Clauset, A., Shalizi, C. R., &amp; Newman, M. E. J. (2009).</span>
<span class="sd">        Power-law distributions in empirical data. SIAM Review, 51(4),</span>
<span class="sd">        661–703. https://doi.org/10.1137/070710111</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">params</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># This is generally a very good approximation of the power law</span>
        <span class="c1"># exponent for alpha &gt; 1. For values of alpha &lt; 1, it will only</span>
        <span class="c1"># approach 1, as expected from the 1 + ...</span>

        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="c1"># If we have a discrete distribution (ie only takes on integer</span>
        <span class="c1"># values) we have to shift slightly.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">discrete</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimate_discrete</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">:</span>
            <span class="n">params</span><span class="p">[</span><span class="s2">&quot;alpha&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">n</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">data</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xmin</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)))</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># For continuous, we just have the usual expression.</span>
            <span class="n">params</span><span class="p">[</span><span class="s2">&quot;alpha&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">n</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">data</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="p">)))</span>

        <span class="n">params</span><span class="p">[</span><span class="s2">&quot;Lambda&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">params</span></div>



<div class="viewcode-block" id="Truncated_Power_Law._cdf_base_function">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Truncated_Power_Law._cdf_base_function">[docs]</a>
    <span class="k">def</span> <span class="nf">_cdf_base_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">mpmath</span> <span class="kn">import</span> <span class="n">gammainc</span>
        <span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">vectorize</span>
        <span class="n">gammainc</span> <span class="o">=</span> <span class="n">vectorize</span><span class="p">(</span><span class="n">gammainc</span><span class="p">)</span>

        <span class="n">CDF</span> <span class="o">=</span> <span class="p">(</span> <span class="p">(</span><span class="n">gammainc</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">Lambda</span><span class="o">*</span><span class="n">x</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float&#39;</span><span class="p">)</span> <span class="o">/</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">Lambda</span><span class="o">**</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>
                    <span class="p">)</span>
        <span class="n">CDF</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span><span class="n">CDF</span>
        <span class="k">return</span> <span class="n">CDF</span></div>



<div class="viewcode-block" id="Truncated_Power_Law._pdf_base_function">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Truncated_Power_Law._pdf_base_function">[docs]</a>
    <span class="k">def</span> <span class="nf">_pdf_base_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">exp</span>
        <span class="k">return</span> <span class="n">x</span><span class="o">**</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">Lambda</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span></div>



    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_pdf_continuous_normalizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">mpmath</span> <span class="kn">import</span> <span class="n">gammainc</span>
        <span class="n">C</span> <span class="o">=</span> <span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">Lambda</span><span class="o">**</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span> <span class="o">/</span>
                <span class="nb">float</span><span class="p">(</span><span class="n">gammainc</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">Lambda</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="p">)))</span>
        <span class="k">return</span> <span class="n">C</span>


    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_pdf_discrete_normalizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="kn">from</span> <span class="nn">mpmath</span> <span class="kn">import</span> <span class="n">lerchphi</span>
        <span class="kn">from</span> <span class="nn">mpmath</span> <span class="kn">import</span> <span class="n">exp</span> <span class="c1"># faster /here/ than numpy.exp</span>
        <span class="n">C</span> <span class="o">=</span> <span class="p">(</span> <span class="nb">float</span><span class="p">(</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xmin</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">Lambda</span><span class="p">)</span> <span class="o">/</span>
            <span class="n">lerchphi</span><span class="p">(</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">Lambda</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="p">))</span> <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">:</span>
            <span class="n">Cxmax</span> <span class="o">=</span> <span class="p">(</span> <span class="nb">float</span><span class="p">(</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xmax</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">Lambda</span><span class="p">)</span> <span class="o">/</span>
                <span class="n">lerchphi</span><span class="p">(</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">Lambda</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">))</span> <span class="p">)</span>
            <span class="n">C</span> <span class="o">=</span> <span class="mf">1.0</span><span class="o">/</span><span class="n">C</span> <span class="o">-</span> <span class="mf">1.0</span><span class="o">/</span><span class="n">Cxmax</span>
            <span class="n">C</span> <span class="o">=</span> <span class="mf">1.0</span><span class="o">/</span><span class="n">C</span>
        <span class="k">return</span> <span class="n">C</span>


    <span class="c1"># Deprecated</span>
<span class="c1">#    def pdf(self, data=None):</span>
<span class="c1">#        if data is None and self.parent_Fit:</span>
<span class="c1">#            data = self.parent_Fit.data</span>
<span class="c1">#</span>
<span class="c1">#        if not self.discrete and self.in_range() and False:</span>
<span class="c1">#            data = trim_to_range(data, xmin=self.xmin, xmax=self.xmax)</span>
<span class="c1">#            from numpy import exp</span>
<span class="c1">#            from mpmath import gammainc</span>
<span class="c1">#        likelihoods = (data**-alpha)*exp(-Lambda*data)*\</span>
<span class="c1">#                (Lambda**(1-alpha))/\</span>
<span class="c1">#                float(gammainc(1-alpha,Lambda*xmin))</span>
<span class="c1">#            likelihoods = ( self.Lambda**(1-self.alpha) /</span>
<span class="c1">#                    (data**self.alpha *</span>
<span class="c1">#                            exp(self.Lambda*data) *</span>
<span class="c1">#                            gammainc(1-self.alpha,self.Lambda*self.xmin)</span>
<span class="c1">#                            ).astype(float)</span>
<span class="c1">#                    )</span>
<span class="c1">#            #Simplified so as not to throw a nan from infs being divided by each other</span>
<span class="c1">#            from sys import float_info</span>
<span class="c1">#            likelihoods[likelihoods==0] = 10**float_info.min_10_exp</span>
<span class="c1">#        else:</span>
<span class="c1">#            likelihoods = Distribution.pdf(self, data)</span>
<span class="c1">#        return likelihoods</span>


<div class="viewcode-block" id="Truncated_Power_Law._generate_random_continuous">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Truncated_Power_Law._generate_random_continuous">[docs]</a>
    <span class="k">def</span> <span class="nf">_generate_random_continuous</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">r</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">helper</span><span class="p">(</span><span class="n">r</span><span class="p">):</span>
            <span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">log</span>
            <span class="kn">from</span> <span class="nn">numpy.random</span> <span class="kn">import</span> <span class="n">rand</span>
            <span class="k">while</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmin</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">Lambda</span><span class="p">)</span> <span class="o">*</span> <span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">r</span><span class="p">)</span>
                <span class="n">p</span> <span class="o">=</span> <span class="p">(</span> <span class="n">x</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">xmin</span> <span class="p">)</span><span class="o">**-</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span>
                <span class="k">if</span> <span class="n">rand</span><span class="p">()</span><span class="o">&lt;</span><span class="n">p</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">x</span>
                <span class="n">r</span> <span class="o">=</span> <span class="n">rand</span><span class="p">()</span>
        <span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">array</span>
        <span class="k">return</span> <span class="n">array</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="n">helper</span><span class="p">,</span> <span class="n">r</span><span class="p">)))</span></div>
</div>



<div class="viewcode-block" id="Lognormal">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Lognormal">[docs]</a>
<span class="k">class</span> <span class="nc">Lognormal</span><span class="p">(</span><span class="n">Distribution</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A lognormal distribution, :math:`p(x) \sim x^{-1} e^{-(\log(x) - \mu)^2 / 2 \sigma^2}`.</span>

<span class="sd">    Note that :math:`\sigma` is referred to as `width` in the package</span>
<span class="sd">    so as to not confuse it with the standard error of other distributions.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;lognormal&#39;</span>

    <span class="c1"># I have renamed this to be width from &#39;sigma&#39; since there is</span>
    <span class="c1"># already a sigma defined as the standard error in this package.</span>
    <span class="n">parameter_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;mu&#39;</span><span class="p">,</span> <span class="s1">&#39;width&#39;</span><span class="p">]</span>

    <span class="n">DEFAULT_PARAMETER_RANGES</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;mu&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
                                <span class="s1">&#39;width&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">]}</span>


<div class="viewcode-block" id="Lognormal.generate_initial_parameters">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Lognormal.generate_initial_parameters">[docs]</a>
    <span class="k">def</span> <span class="nf">generate_initial_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generate initial guesses for the distribution parameters based</span>
<span class="sd">        on the data.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : array_like</span>
<span class="sd">            The data to use to generate the initial values of parameters.</span>

<span class="sd">            Should already be trimmed to the data range defined by</span>
<span class="sd">            `xmin` and `xmax` (if included).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        params : dict</span>
<span class="sd">            A dictionary of the parameters and their values.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        [1] Clauset, A., Shalizi, C. R., &amp; Newman, M. E. J. (2009).</span>
<span class="sd">        Power-law distributions in empirical data. SIAM Review, 51(4),</span>
<span class="sd">        661–703. https://doi.org/10.1137/070710111</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">params</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="n">logdata</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="n">params</span><span class="p">[</span><span class="s2">&quot;mu&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">logdata</span><span class="p">)</span>
        <span class="n">params</span><span class="p">[</span><span class="s2">&quot;width&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">logdata</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">params</span></div>



<div class="viewcode-block" id="Lognormal.pdf">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Lognormal.pdf">[docs]</a>
    <span class="k">def</span> <span class="nf">pdf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the probability density function (normalized histogram) of the</span>
<span class="sd">        theoretical distribution for the values in data within xmin and xmax,</span>
<span class="sd">        if present.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : list or array, optional</span>
<span class="sd">            If not provided, attempts to use the data from the Fit object in</span>
<span class="sd">            which the Distribution object is contained.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        probabilities : array</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># TODO clean this up</span>
        <span class="k">if</span> <span class="n">data</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent_Fit</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent_Fit</span><span class="o">.</span><span class="n">data</span>

        <span class="n">data</span> <span class="o">=</span> <span class="n">trim_to_range</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">xmin</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">)</span>
        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="kn">from</span> <span class="nn">sys</span> <span class="kn">import</span> <span class="n">float_info</span>
        <span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">tile</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_range</span><span class="p">():</span>
            <span class="k">return</span> <span class="n">tile</span><span class="p">(</span><span class="mi">10</span><span class="o">**</span><span class="n">float_info</span><span class="o">.</span><span class="n">min_10_exp</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">discrete</span><span class="p">:</span>
            <span class="n">f</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pdf_base_function</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">C</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pdf_continuous_normalizer</span>
            <span class="k">if</span> <span class="n">C</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">likelihoods</span> <span class="o">=</span> <span class="n">f</span><span class="o">/</span><span class="n">C</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">likelihoods</span> <span class="o">=</span> <span class="n">tile</span><span class="p">(</span><span class="mi">10</span><span class="o">**</span><span class="n">float_info</span><span class="o">.</span><span class="n">min_10_exp</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pdf_discrete_normalizer</span><span class="p">:</span>
                <span class="n">f</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pdf_base_function</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
                <span class="n">C</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pdf_discrete_normalizer</span>
                <span class="n">likelihoods</span> <span class="o">=</span> <span class="n">f</span><span class="o">*</span><span class="n">C</span>

            <span class="c1"># This is the only part I&#39;ve cleaned up so far since I changed</span>
            <span class="c1"># the name of discrete_approximation to discrete_normalization.</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">discrete_normalization</span> <span class="o">==</span> <span class="s1">&#39;round&#39;</span><span class="p">:</span>
                <span class="n">likelihoods</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_round_discrete_approx</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">discrete_normalization</span> <span class="o">==</span> <span class="s1">&#39;sum&#39;</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">:</span>
                    <span class="n">upper_limit</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">upper_limit</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

<span class="c1">#            from mpmath import exp</span>
                <span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">arange</span>
                <span class="n">X</span> <span class="o">=</span> <span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="p">,</span> <span class="n">upper_limit</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">PDF</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pdf_base_function</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
                <span class="n">PDF</span> <span class="o">=</span> <span class="p">(</span><span class="n">PDF</span><span class="o">/</span><span class="nb">sum</span><span class="p">(</span><span class="n">PDF</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
                <span class="n">likelihoods</span> <span class="o">=</span> <span class="n">PDF</span><span class="p">[(</span><span class="n">data</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)]</span>
        <span class="n">likelihoods</span><span class="p">[</span><span class="n">likelihoods</span><span class="o">==</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">10</span><span class="o">**</span><span class="n">float_info</span><span class="o">.</span><span class="n">min_10_exp</span>
        <span class="k">return</span> <span class="n">likelihoods</span></div>



<div class="viewcode-block" id="Lognormal._round_discrete_approx">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Lognormal._round_discrete_approx">[docs]</a>
    <span class="k">def</span> <span class="nf">_round_discrete_approx</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This function reformulates the calculation to avoid underflow errors</span>
<span class="sd">        with the erf function. As implemented, erf(x) quickly approaches 1</span>
<span class="sd">        while erfc(x) is more accurate. Since erfc(x) = 1 - erf(x),</span>
<span class="sd">        calculations can be written using erfc(x)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
        <span class="kn">import</span> <span class="nn">scipy.special</span> <span class="k">as</span> <span class="nn">ss</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; Temporarily expand xmin and xmax to be able to grab the extra bit of</span>
<span class="sd">        probability mass beyond the (integer) values of xmin and xmax</span>
<span class="sd">        Note this is a design decision. One could also say this extra</span>
<span class="sd">        probability &quot;off the edge&quot; of the distribution shouldn&#39;t be included,</span>
<span class="sd">        and that implementation is retained below, commented out. Note, however,</span>
<span class="sd">        that such a cliff means values right at xmin and xmax have half the width to</span>
<span class="sd">        grab probability from, and thus are lower probability than they would otherwise</span>
<span class="sd">        be. This is particularly concerning for values at xmin, which are typically</span>
<span class="sd">        the most likely and greatly influence the distribution&#39;s fit.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">lower_data</span> <span class="o">=</span> <span class="n">data</span><span class="o">-</span><span class="mf">.5</span>
        <span class="n">upper_data</span> <span class="o">=</span> <span class="n">data</span><span class="o">+</span><span class="mf">.5</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">xmin</span> <span class="o">-=</span> <span class="mf">.5</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span> <span class="o">+=</span> <span class="mf">.5</span>


        <span class="c1"># revised calculation written to avoid underflow errors</span>
        <span class="n">arg1</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">lower_data</span><span class="p">)</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">width</span><span class="p">)</span>
        <span class="n">arg2</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">upper_data</span><span class="p">)</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">width</span><span class="p">)</span>
        <span class="n">likelihoods</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="p">(</span><span class="n">ss</span><span class="o">.</span><span class="n">erfc</span><span class="p">(</span><span class="n">arg1</span><span class="p">)</span> <span class="o">-</span> <span class="n">ss</span><span class="o">.</span><span class="n">erfc</span><span class="p">(</span><span class="n">arg2</span><span class="p">))</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">:</span>
            <span class="n">norm</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">ss</span><span class="o">.</span><span class="n">erfc</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="p">)</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">width</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># may still need to be fixed</span>
            <span class="n">norm</span> <span class="o">=</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cdf_xmin</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cdf_base_function</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">xmin</span> <span class="o">+=</span><span class="mf">.5</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span> <span class="o">-=</span> <span class="mf">.5</span>

        <span class="k">return</span> <span class="n">likelihoods</span><span class="o">/</span><span class="n">norm</span></div>


<div class="viewcode-block" id="Lognormal.cdf">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Lognormal.cdf">[docs]</a>
    <span class="k">def</span> <span class="nf">cdf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">survival</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The cumulative distribution function (CDF) of the lognormal</span>
<span class="sd">        distribution. Calculated for the values given in data within xmin and</span>
<span class="sd">        xmax, if present. Calculation was reformulated to avoid underflow</span>
<span class="sd">        errors</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : list or array, optional</span>
<span class="sd">            If not provided, attempts to use the data from the Fit object in</span>
<span class="sd">            which the Distribution object is contained.</span>
<span class="sd">        survival : bool, optional</span>
<span class="sd">            Whether to calculate a CDF (False) or CCDF (True).</span>
<span class="sd">            False by default.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        X : array</span>
<span class="sd">            The sorted, unique values in the data.</span>
<span class="sd">        probabilities : array</span>
<span class="sd">            The portion of the data that is less than or equal to X.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">log</span><span class="p">,</span> <span class="n">sqrt</span>
        <span class="kn">import</span> <span class="nn">scipy.special</span> <span class="k">as</span> <span class="nn">ss</span>
        <span class="k">if</span> <span class="n">data</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent_Fit</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent_Fit</span><span class="o">.</span><span class="n">data</span>

        <span class="n">data</span> <span class="o">=</span> <span class="n">trim_to_range</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">xmin</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">)</span>
        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="kn">from</span> <span class="nn">sys</span> <span class="kn">import</span> <span class="n">float_info</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_range</span><span class="p">():</span>
            <span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">tile</span>
            <span class="k">return</span> <span class="n">tile</span><span class="p">(</span><span class="mi">10</span><span class="o">**</span><span class="n">float_info</span><span class="o">.</span><span class="n">min_10_exp</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>

        <span class="n">val_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">log</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">width</span><span class="p">)</span>
        <span class="n">val_xmin</span> <span class="o">=</span> <span class="p">(</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="p">)</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">width</span><span class="p">)</span>
        <span class="n">CDF</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">ss</span><span class="o">.</span><span class="n">erfc</span><span class="p">(</span><span class="n">val_xmin</span><span class="p">)</span> <span class="o">-</span> <span class="n">ss</span><span class="o">.</span><span class="n">erfc</span><span class="p">(</span><span class="n">val_data</span><span class="p">))</span>

        <span class="n">norm</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">ss</span><span class="o">.</span><span class="n">erfc</span><span class="p">(</span><span class="n">val_xmin</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">:</span>
            <span class="c1"># TO DO: Improve this line further for better numerical accuracy?</span>
            <span class="n">norm</span> <span class="o">=</span> <span class="n">norm</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cdf_base_function</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xmax</span><span class="p">))</span>

        <span class="n">CDF</span> <span class="o">=</span> <span class="n">CDF</span><span class="o">/</span><span class="n">norm</span>

        <span class="k">if</span> <span class="n">survival</span><span class="p">:</span>
            <span class="n">CDF</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">CDF</span>

        <span class="n">possible_numerical_error</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">isnan</span><span class="p">,</span> <span class="nb">min</span>
        <span class="k">if</span> <span class="n">isnan</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">CDF</span><span class="p">)):</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&#39;nan&#39; in fit cumulative distribution values.&quot;</span><span class="p">,</span> <span class="n">file</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">)</span>
            <span class="n">possible_numerical_error</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="c1">#if 0 in CDF or 1 in CDF:</span>
        <span class="c1">#    print(&quot;0 or 1 in fit cumulative distribution values.&quot;, file=sys.stderr)</span>
        <span class="c1">#    possible_numerical_error = True</span>
        <span class="k">if</span> <span class="n">possible_numerical_error</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Likely underflow or overflow error: the optimal fit for this distribution gives values that are so extreme that we lack the numerical precision to calculate them.&quot;</span><span class="p">,</span> <span class="n">file</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">CDF</span></div>


<div class="viewcode-block" id="Lognormal._cdf_base_function">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Lognormal._cdf_base_function">[docs]</a>
    <span class="k">def</span> <span class="nf">_cdf_base_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">sqrt</span><span class="p">,</span> <span class="n">log</span>
        <span class="kn">from</span> <span class="nn">scipy.special</span> <span class="kn">import</span> <span class="n">erf</span>
        <span class="k">return</span>  <span class="mf">0.5</span> <span class="o">+</span> <span class="p">(</span> <span class="mf">0.5</span> <span class="o">*</span>
                <span class="n">erf</span><span class="p">((</span><span class="n">log</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">width</span><span class="p">)))</span></div>



<div class="viewcode-block" id="Lognormal._pdf_base_function">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Lognormal._pdf_base_function">[docs]</a>
    <span class="k">def</span> <span class="nf">_pdf_base_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">exp</span><span class="p">,</span> <span class="n">log</span>
        <span class="k">return</span> <span class="p">((</span><span class="mf">1.0</span><span class="o">/</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span>
                <span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">(</span> <span class="p">(</span><span class="n">log</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">width</span><span class="o">**</span><span class="mi">2</span><span class="p">)))</span></div>



    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_pdf_continuous_normalizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">mpmath</span> <span class="kn">import</span> <span class="n">erfc</span>
<span class="c1">#        from scipy.special import erfc</span>
        <span class="kn">from</span> <span class="nn">scipy.constants</span> <span class="kn">import</span> <span class="n">pi</span>
        <span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">sqrt</span><span class="p">,</span> <span class="n">log</span>
        <span class="n">C</span> <span class="o">=</span> <span class="p">(</span><span class="n">erfc</span><span class="p">((</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">width</span><span class="p">))</span> <span class="o">/</span>
             <span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="n">pi</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">width</span><span class="o">**</span><span class="mi">2</span><span class="p">)))</span>
        <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>


    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_pdf_discrete_normalizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">False</span>


<div class="viewcode-block" id="Lognormal._generate_random_continuous">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Lognormal._generate_random_continuous">[docs]</a>
    <span class="k">def</span> <span class="nf">_generate_random_continuous</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">r</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">exp</span><span class="p">,</span> <span class="n">sqrt</span><span class="p">,</span> <span class="n">log</span><span class="p">,</span> <span class="n">frompyfunc</span>
        <span class="kn">from</span> <span class="nn">mpmath</span> <span class="kn">import</span> <span class="n">erf</span><span class="p">,</span> <span class="n">erfinv</span>
        <span class="c1">#This is a long, complicated function broken into parts.</span>
        <span class="c1">#We use mpmath to maintain numerical accuracy as we run through</span>
        <span class="c1">#erf and erfinv, until we get to more sane numbers. Thanks to</span>
        <span class="c1">#Wolfram Alpha for producing the appropriate inverse of the CCDF</span>
        <span class="c1">#for me, which is what we need to calculate these things.</span>
        <span class="n">erfinv</span> <span class="o">=</span> <span class="n">frompyfunc</span><span class="p">(</span><span class="n">erfinv</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">Q</span> <span class="o">=</span> <span class="n">erf</span><span class="p">(</span> <span class="p">(</span> <span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xmin</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">width</span><span class="p">))</span>
        <span class="n">Q</span> <span class="o">=</span> <span class="n">Q</span><span class="o">*</span><span class="n">r</span> <span class="o">-</span> <span class="n">r</span> <span class="o">+</span> <span class="mf">1.0</span>
        <span class="n">Q</span> <span class="o">=</span> <span class="n">erfinv</span><span class="p">(</span><span class="n">Q</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="o">+</span> <span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">width</span><span class="o">*</span><span class="n">Q</span><span class="p">)</span></div>
</div>


<span class="c1">#    def _generate_random_continuous(self, r1, r2=None):</span>
<span class="c1">#        from numpy import log, sqrt, exp, sin, cos</span>
<span class="c1">#        from scipy.constants import pi</span>
<span class="c1">#        if r2==None:</span>
<span class="c1">#            from numpy.random import rand</span>
<span class="c1">#            r2 = rand(len(r1))</span>
<span class="c1">#            r2_provided = False</span>
<span class="c1">#        else:</span>
<span class="c1">#            r2_provided = True</span>
<span class="c1">#</span>
<span class="c1">#        rho = sqrt(-2.0 * self.width**2.0 * log(1-r1))</span>
<span class="c1">#        theta = 2.0 * pi * r2</span>
<span class="c1">#        x1 = exp(rho * sin(theta))</span>
<span class="c1">#        x2 = exp(rho * cos(theta))</span>
<span class="c1">#</span>
<span class="c1">#        if r2_provided:</span>
<span class="c1">#            return x1, x2</span>
<span class="c1">#        else:</span>
<span class="c1">#            return x1</span>


<div class="viewcode-block" id="Lognormal_Positive">
<a class="viewcode-back" href="../../powerlaw.html#powerlaw.Lognormal_Positive">[docs]</a>
<span class="k">class</span> <span class="nc">Lognormal_Positive</span><span class="p">(</span><span class="n">Lognormal</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A lognormal distribution with strictly positive :math:`\mu`, :math:`p(x)</span>
<span class="sd">    \sim x^{-1} e^{-(\log(x) - \mu)^2 / 2 \sigma^2}`.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;lognormal_positive&#39;</span>

    <span class="c1"># I have renamed this to be width from &#39;sigma&#39; since there is</span>
    <span class="c1"># already a sigma defined as the standard error in this package.</span>
    <span class="n">parameter_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;mu&#39;</span><span class="p">,</span> <span class="s1">&#39;width&#39;</span><span class="p">]</span>

    <span class="n">DEFAULT_PARAMETER_RANGES</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;mu&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
                                <span class="s1">&#39;width&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">]}</span></div>

</pre></div>
        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          
          
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2025, Jeff Alstott
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer no-toc">
      
      
      
    </aside>
  </div>
</div><script src="../../_static/documentation_options.js?v=72d88caf"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/scripts/furo.js?v=5fa4622c"></script>
    </body>
</html>